{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c017511",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37bf145a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models, datasets\n",
    "from torch.autograd import Variable\n",
    "import shutil\n",
    "from torchsummary import summary\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a6f660",
   "metadata": {},
   "source": [
    "Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d4c730d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "torch.cuda.manual_seed(1337)\n",
    "\n",
    "batch_size = 100\n",
    "test_batch_size = 1000\n",
    "gamma = 0.001\n",
    "lr = 0.01\n",
    "prune_rate=0.6\n",
    "\n",
    "kwargs = {'num_workers': 16, 'pin_memory': True}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203a92f1",
   "metadata": {},
   "source": [
    "DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a58c5d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.CIFAR10('./data', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.Pad(4),\n",
    "                       transforms.RandomCrop(32),\n",
    "                       transforms.RandomHorizontalFlip(),\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                   ])),\n",
    "    batch_size=batch_size, shuffle=True, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.CIFAR10('./data', train=False, transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                   ])),\n",
    "    batch_size=test_batch_size, shuffle=True, **kwargs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8bbe0f",
   "metadata": {},
   "source": [
    "Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1a11852",
   "metadata": {},
   "outputs": [],
   "source": [
    "class sequential_model(nn.Module):\n",
    "    def __init__(self, layers=None):\n",
    "        super(sequential_model, self).__init__()\n",
    "        if layers == None:\n",
    "            layers = [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512]\n",
    "        num_classes = 10\n",
    "        self.feature = self.make_layers(layers)\n",
    "        self.classifier = nn.Linear(layers[-1], num_classes)\n",
    "    \n",
    "    def make_layers(self, structure):\n",
    "        layers = []\n",
    "        in_channels = 3\n",
    "        for v in structure:\n",
    "            if v == 'M':\n",
    "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "            else:\n",
    "                conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1, bias=False)\n",
    "                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n",
    "                in_channels = v\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.feature(x)\n",
    "        x = nn.AvgPool2d(2)(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        y = self.classifier(x)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec86493",
   "metadata": {},
   "source": [
    "Train Epoch method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcf83829",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, epoch, optimizer, data_loader=train_loader):\n",
    "    model.train()\n",
    "    for idx, (data, target) in enumerate(data_loader):\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        \n",
    "        sum_channel_scaling_factors = 0\n",
    "        \n",
    "        #sum absolute value from all channel scaling factors for sparsity\n",
    "        for m in model.modules():\n",
    "            if isinstance(m, nn.BatchNorm2d):\n",
    "                sum_channel_scaling_factors += torch.sum(m.weight.data.abs())\n",
    "        \n",
    "        loss = F.cross_entropy(output, target) + gamma * sum_channel_scaling_factors\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "            \n",
    "        if idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.1f}%)]\\tLoss: {:.6f}'.format(\n",
    "            epoch, idx * len(data), len(data_loader.dataset),\n",
    "            100. * idx / len(data_loader), loss.data.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d7b31e",
   "metadata": {},
   "source": [
    "Validation Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eeeddf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns precision and loss of model\n",
    "def test(model, data_loader=test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in data_loader:\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "        data, target = Variable(data), Variable(target)        \n",
    "        output = model(data)\n",
    "        test_loss += F.cross_entropy(output, target, size_average=False).data.item()\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "        test_loss /= len(data_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.1f}%)\\n'.format(\n",
    "        test_loss, correct, len(data_loader.dataset),\n",
    "        100. * correct / len(data_loader.dataset)))\n",
    "    return (correct / float(len(data_loader.dataset)), test_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bc0761",
   "metadata": {},
   "source": [
    "Save Model Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6656403c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, filename='checkpoint_sr.pth.tar'):\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, 'model_best_sr.pth.tar')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f892aa61",
   "metadata": {},
   "source": [
    "Train network method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc841441",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, epochs=10):\n",
    "    \n",
    "    model.cuda()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    best_prec = 0.\n",
    "    for i in range(0, epochs):\n",
    "        train(model, i, optimizer)\n",
    "        prec, loss = test(model)\n",
    "        is_best = prec > best_prec\n",
    "        best_prec1 = max(prec, best_prec)\n",
    "        save_checkpoint({\n",
    "            'epoch': i + 1,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'best_prec1': best_prec,\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "        }, is_best)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db21bd4",
   "metadata": {},
   "source": [
    "Load existing Model method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec19a675",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(checkpoint_path=\"checkpoint_sr.pth.tar\", model_path=\"model_best_sr.pth.tar\"):\n",
    "    model = sequential_model()\n",
    "    model.cuda()\n",
    "    if os.path.isfile(model_path):\n",
    "        print(\"=> loading checkpoint '{}'\".format(model_path))\n",
    "        checkpoint_path = torch.load(model_path)\n",
    "        best_prec1 = checkpoint_path['best_prec1']\n",
    "        model.load_state_dict(checkpoint_path['state_dict'])\n",
    "        print(\"=> loaded checkpoint '{}' (epoch {}) Prec1: {:f}\"\n",
    "              .format(model, checkpoint_path['epoch'], best_prec1))\n",
    "    else:\n",
    "        print(\"=> no checkpoint found at\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2690475",
   "metadata": {},
   "source": [
    "Select weak channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c609836",
   "metadata": {},
   "outputs": [],
   "source": [
    "def selectChannels(model, percent=0.2):\n",
    "    total = 0\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, nn.BatchNorm2d):\n",
    "            total += m.weight.data.shape[0]\n",
    "\n",
    "    bn = torch.zeros(total)\n",
    "    index = 0\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, nn.BatchNorm2d):\n",
    "            size = m.weight.data.shape[0]\n",
    "            bn[index:(index+size)] = m.weight.data.abs().clone()\n",
    "            index += size\n",
    "\n",
    "    y, i = torch.sort(bn)\n",
    "    thre_index = int(total * percent)\n",
    "    thre = y[thre_index]\n",
    "\n",
    "    pruned = 0\n",
    "    cfg = []\n",
    "    cfg_mask = []\n",
    "    for k, m in enumerate(model.modules()):\n",
    "        if isinstance(m, nn.BatchNorm2d):\n",
    "            weight_copy = m.weight.data.clone()\n",
    "            print(type(weight_copy.abs().gt(thre).float()))\n",
    "            #mask is a matrix in which 1 marks the channels which are kept and 0 marks the pruned channels\n",
    "            mask = weight_copy.abs().gt(thre).float().cuda()          \n",
    "            #pruned is the number of all pruned channels \n",
    "            pruned = pruned + mask.shape[0] - torch.sum(mask)\n",
    "            m.weight.data.mul_(mask)\n",
    "            m.bias.data.mul_(mask)\n",
    "            cfg.append(int(torch.sum(mask)))\n",
    "            cfg_mask.append(mask.clone())\n",
    "            print('layer index: {:d} \\t total channel: {:d} \\t remaining channel: {:d}'.\n",
    "                format(k, mask.shape[0], int(torch.sum(mask))))\n",
    "        elif isinstance(m, nn.MaxPool2d):\n",
    "            cfg.append('M')\n",
    "    return cfg, cfg_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a1f710",
   "metadata": {},
   "source": [
    "Build new model and transfer weights from full model to build the new pruned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c09ea51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer_params(cfg, cfg_mask, model):\n",
    "    newmodel = sequential_model(layers=cfg)\n",
    "    newmodel.cuda() \n",
    "\n",
    "    layer_id_in_cfg = 0\n",
    "    start_mask = torch.ones(3)\n",
    "    end_mask = cfg_mask[layer_id_in_cfg]\n",
    "    for [m0, m1] in zip(model.modules(), newmodel.modules()):\n",
    "        if isinstance(m0, nn.BatchNorm2d):\n",
    "            idx1 = np.squeeze(np.argwhere(np.asarray(end_mask.cpu().numpy())))\n",
    "            m1.weight.data = m0.weight.data[idx1].clone()\n",
    "            m1.bias.data = m0.bias.data[idx1].clone()\n",
    "            m1.running_mean = m0.running_mean[idx1].clone()\n",
    "            m1.running_var = m0.running_var[idx1].clone()\n",
    "            layer_id_in_cfg += 1\n",
    "            start_mask = end_mask.clone()\n",
    "            if layer_id_in_cfg < len(cfg_mask):  # do not change in Final FC\n",
    "                end_mask = cfg_mask[layer_id_in_cfg]\n",
    "        elif isinstance(m0, nn.Conv2d):\n",
    "            idx0 = np.squeeze(np.argwhere(np.asarray(start_mask.cpu().numpy())))\n",
    "            idx1 = np.squeeze(np.argwhere(np.asarray(end_mask.cpu().numpy())))\n",
    "            print('In shape: {:d} Out shape:{:d}'.format(idx0.shape[0], idx1.shape[0]))\n",
    "            w = m0.weight.data[:, idx0, :, :].clone()\n",
    "            w = w[idx1, :, :, :].clone()\n",
    "            m1.weight.data = w.clone()\n",
    "            # m1.bias.data = m0.bias.data[idx1].clone()\n",
    "        elif isinstance(m0, nn.Linear):\n",
    "            idx0 = np.squeeze(np.argwhere(np.asarray(start_mask.cpu().numpy())))\n",
    "            m1.weight.data = m0.weight.data[:, idx0].clone()    \n",
    "    return newmodel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a38e5f8",
   "metadata": {},
   "source": [
    "Prune trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b64546cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_model(model, percent=0.3):\n",
    "    cfg, cfg_mask = selectChannels(model, percent)\n",
    "    prune_model = transfer_params(cfg, cfg_mask, model)\n",
    "    torch.save({'cfg': cfg, 'state_dict': prune_model.state_dict()}, f='pruned_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c664c7a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/50000 (0.0%)]\tLoss: 5.290290\n",
      "Train Epoch: 0 [10000/50000 (20.0%)]\tLoss: 4.883985\n",
      "Train Epoch: 0 [20000/50000 (40.0%)]\tLoss: 4.622361\n",
      "Train Epoch: 0 [30000/50000 (60.0%)]\tLoss: 4.396645\n",
      "Train Epoch: 0 [40000/50000 (80.0%)]\tLoss: 4.168612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eddy/Programme/anaconda3/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.1525, Accuracy: 4469/10000 (44.7%)\n",
      "\n",
      "Train Epoch: 1 [0/50000 (0.0%)]\tLoss: 4.004735\n",
      "Train Epoch: 1 [10000/50000 (20.0%)]\tLoss: 4.011814\n",
      "Train Epoch: 1 [20000/50000 (40.0%)]\tLoss: 4.098103\n",
      "Train Epoch: 1 [30000/50000 (60.0%)]\tLoss: 3.790919\n",
      "Train Epoch: 1 [40000/50000 (80.0%)]\tLoss: 3.674428\n",
      "\n",
      "Test set: Average loss: 0.1321, Accuracy: 5467/10000 (54.7%)\n",
      "\n",
      "Train Epoch: 2 [0/50000 (0.0%)]\tLoss: 3.665668\n",
      "Train Epoch: 2 [10000/50000 (20.0%)]\tLoss: 3.686166\n",
      "Train Epoch: 2 [20000/50000 (40.0%)]\tLoss: 3.622760\n",
      "Train Epoch: 2 [30000/50000 (60.0%)]\tLoss: 3.729661\n",
      "Train Epoch: 2 [40000/50000 (80.0%)]\tLoss: 3.529776\n",
      "\n",
      "Test set: Average loss: 0.0838, Accuracy: 7114/10000 (71.1%)\n",
      "\n",
      "Train Epoch: 3 [0/50000 (0.0%)]\tLoss: 3.401630\n",
      "Train Epoch: 3 [10000/50000 (20.0%)]\tLoss: 3.471672\n",
      "Train Epoch: 3 [20000/50000 (40.0%)]\tLoss: 3.310930\n",
      "Train Epoch: 3 [30000/50000 (60.0%)]\tLoss: 3.454952\n",
      "Train Epoch: 3 [40000/50000 (80.0%)]\tLoss: 3.464316\n",
      "\n",
      "Test set: Average loss: 0.0896, Accuracy: 6990/10000 (69.9%)\n",
      "\n",
      "Train Epoch: 4 [0/50000 (0.0%)]\tLoss: 3.447933\n",
      "Train Epoch: 4 [10000/50000 (20.0%)]\tLoss: 3.136619\n",
      "Train Epoch: 4 [20000/50000 (40.0%)]\tLoss: 3.332905\n",
      "Train Epoch: 4 [30000/50000 (60.0%)]\tLoss: 3.446648\n",
      "Train Epoch: 4 [40000/50000 (80.0%)]\tLoss: 3.330534\n",
      "\n",
      "Test set: Average loss: 0.0666, Accuracy: 7863/10000 (78.6%)\n",
      "\n",
      "Train Epoch: 5 [0/50000 (0.0%)]\tLoss: 3.167751\n",
      "Train Epoch: 5 [10000/50000 (20.0%)]\tLoss: 3.372847\n",
      "Train Epoch: 5 [20000/50000 (40.0%)]\tLoss: 3.224187\n",
      "Train Epoch: 5 [30000/50000 (60.0%)]\tLoss: 3.348404\n",
      "Train Epoch: 5 [40000/50000 (80.0%)]\tLoss: 3.465909\n",
      "\n",
      "Test set: Average loss: 0.0568, Accuracy: 8108/10000 (81.1%)\n",
      "\n",
      "Train Epoch: 6 [0/50000 (0.0%)]\tLoss: 3.230487\n",
      "Train Epoch: 6 [10000/50000 (20.0%)]\tLoss: 3.187449\n",
      "Train Epoch: 6 [20000/50000 (40.0%)]\tLoss: 3.139210\n",
      "Train Epoch: 6 [30000/50000 (60.0%)]\tLoss: 3.289175\n",
      "Train Epoch: 6 [40000/50000 (80.0%)]\tLoss: 3.304374\n",
      "\n",
      "Test set: Average loss: 0.0507, Accuracy: 8209/10000 (82.1%)\n",
      "\n",
      "Train Epoch: 7 [0/50000 (0.0%)]\tLoss: 3.234548\n",
      "Train Epoch: 7 [10000/50000 (20.0%)]\tLoss: 3.139864\n",
      "Train Epoch: 7 [20000/50000 (40.0%)]\tLoss: 3.159716\n",
      "Train Epoch: 7 [30000/50000 (60.0%)]\tLoss: 3.105704\n",
      "Train Epoch: 7 [40000/50000 (80.0%)]\tLoss: 3.252489\n",
      "\n",
      "Test set: Average loss: 0.0500, Accuracy: 8375/10000 (83.8%)\n",
      "\n",
      "Train Epoch: 8 [0/50000 (0.0%)]\tLoss: 3.184943\n",
      "Train Epoch: 8 [10000/50000 (20.0%)]\tLoss: 3.149639\n",
      "Train Epoch: 8 [20000/50000 (40.0%)]\tLoss: 3.253237\n",
      "Train Epoch: 8 [30000/50000 (60.0%)]\tLoss: 3.176596\n",
      "Train Epoch: 8 [40000/50000 (80.0%)]\tLoss: 3.253954\n",
      "\n",
      "Test set: Average loss: 0.0400, Accuracy: 8546/10000 (85.5%)\n",
      "\n",
      "Train Epoch: 9 [0/50000 (0.0%)]\tLoss: 3.152841\n",
      "Train Epoch: 9 [10000/50000 (20.0%)]\tLoss: 3.179919\n",
      "Train Epoch: 9 [20000/50000 (40.0%)]\tLoss: 3.178951\n",
      "Train Epoch: 9 [30000/50000 (60.0%)]\tLoss: 3.250244\n",
      "Train Epoch: 9 [40000/50000 (80.0%)]\tLoss: 3.184146\n",
      "\n",
      "Test set: Average loss: 0.0451, Accuracy: 8527/10000 (85.3%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = train_model(sequential_model())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e9f76e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "layer index: 3 \t total channel: 64 \t remaining channel: 23\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 6 \t total channel: 64 \t remaining channel: 35\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 10 \t total channel: 128 \t remaining channel: 92\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 13 \t total channel: 128 \t remaining channel: 74\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 17 \t total channel: 256 \t remaining channel: 167\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 20 \t total channel: 256 \t remaining channel: 126\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 24 \t total channel: 512 \t remaining channel: 270\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 27 \t total channel: 512 \t remaining channel: 236\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 31 \t total channel: 512 \t remaining channel: 151\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 34 \t total channel: 512 \t remaining channel: 3\n",
      "In shape: 3 Out shape:23\n",
      "In shape: 23 Out shape:35\n",
      "In shape: 35 Out shape:92\n",
      "In shape: 92 Out shape:74\n",
      "In shape: 74 Out shape:167\n",
      "In shape: 167 Out shape:126\n",
      "In shape: 126 Out shape:270\n",
      "In shape: 270 Out shape:236\n",
      "In shape: 236 Out shape:151\n",
      "In shape: 151 Out shape:3\n"
     ]
    }
   ],
   "source": [
    "prune_model(model, prune_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "854e4a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.2549, Accuracy: 1427/10000 (14.3%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "safed = torch.load('pruned_model.pt')\n",
    "structure = safed['cfg']\n",
    "weights = safed['state_dict']\n",
    "pruned_model = sequential_model(structure)\n",
    "pruned_model.load_state_dict(weights)\n",
    "pruned_model.cuda()\n",
    "prec, loss = test(pruned_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f0b0924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/50000 (0.0%)]\tLoss: 3.646596\n",
      "Train Epoch: 0 [10000/50000 (20.0%)]\tLoss: 2.762629\n",
      "Train Epoch: 0 [20000/50000 (40.0%)]\tLoss: 2.533415\n",
      "Train Epoch: 0 [30000/50000 (60.0%)]\tLoss: 2.454100\n",
      "Train Epoch: 0 [40000/50000 (80.0%)]\tLoss: 2.758305\n",
      "\n",
      "Test set: Average loss: 0.0587, Accuracy: 8129/10000 (81.3%)\n",
      "\n",
      "Train Epoch: 1 [0/50000 (0.0%)]\tLoss: 2.282314\n",
      "Train Epoch: 1 [10000/50000 (20.0%)]\tLoss: 2.233226\n",
      "Train Epoch: 1 [20000/50000 (40.0%)]\tLoss: 2.174289\n",
      "Train Epoch: 1 [30000/50000 (60.0%)]\tLoss: 2.280536\n",
      "Train Epoch: 1 [40000/50000 (80.0%)]\tLoss: 2.359980\n",
      "\n",
      "Test set: Average loss: 0.0633, Accuracy: 8116/10000 (81.2%)\n",
      "\n",
      "Train Epoch: 2 [0/50000 (0.0%)]\tLoss: 2.384363\n",
      "Train Epoch: 2 [10000/50000 (20.0%)]\tLoss: 2.285617\n",
      "Train Epoch: 2 [20000/50000 (40.0%)]\tLoss: 2.438430\n",
      "Train Epoch: 2 [30000/50000 (60.0%)]\tLoss: 2.424576\n",
      "Train Epoch: 2 [40000/50000 (80.0%)]\tLoss: 2.231471\n",
      "\n",
      "Test set: Average loss: 0.0472, Accuracy: 8460/10000 (84.6%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0524, Accuracy: 8460/10000 (84.6%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0.8460), 0.052417757893058935)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fine_tuned_model = train_model(pruned_model, epochs=3)\n",
    "test(fine_tuned_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "64f3b014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 32, 32]           1,728\n",
      "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
      "              ReLU-3           [-1, 64, 32, 32]               0\n",
      "            Conv2d-4           [-1, 64, 32, 32]          36,864\n",
      "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
      "              ReLU-6           [-1, 64, 32, 32]               0\n",
      "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
      "            Conv2d-8          [-1, 128, 16, 16]          73,728\n",
      "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
      "             ReLU-10          [-1, 128, 16, 16]               0\n",
      "           Conv2d-11          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
      "             ReLU-13          [-1, 128, 16, 16]               0\n",
      "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
      "           Conv2d-15            [-1, 256, 8, 8]         294,912\n",
      "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
      "             ReLU-17            [-1, 256, 8, 8]               0\n",
      "           Conv2d-18            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
      "             ReLU-20            [-1, 256, 8, 8]               0\n",
      "        MaxPool2d-21            [-1, 256, 4, 4]               0\n",
      "           Conv2d-22            [-1, 512, 4, 4]       1,179,648\n",
      "      BatchNorm2d-23            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-24            [-1, 512, 4, 4]               0\n",
      "           Conv2d-25            [-1, 512, 4, 4]       2,359,296\n",
      "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-27            [-1, 512, 4, 4]               0\n",
      "        MaxPool2d-28            [-1, 512, 2, 2]               0\n",
      "           Conv2d-29            [-1, 512, 2, 2]       2,359,296\n",
      "      BatchNorm2d-30            [-1, 512, 2, 2]           1,024\n",
      "             ReLU-31            [-1, 512, 2, 2]               0\n",
      "           Conv2d-32            [-1, 512, 2, 2]       2,359,296\n",
      "      BatchNorm2d-33            [-1, 512, 2, 2]           1,024\n",
      "             ReLU-34            [-1, 512, 2, 2]               0\n",
      "           Linear-35                   [-1, 10]           5,130\n",
      "================================================================\n",
      "Total params: 9,413,066\n",
      "Trainable params: 9,413,066\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 5.95\n",
      "Params size (MB): 35.91\n",
      "Estimated Total Size (MB): 41.87\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, (3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a2420286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 23, 32, 32]             621\n",
      "       BatchNorm2d-2           [-1, 23, 32, 32]              46\n",
      "              ReLU-3           [-1, 23, 32, 32]               0\n",
      "            Conv2d-4           [-1, 35, 32, 32]           7,245\n",
      "       BatchNorm2d-5           [-1, 35, 32, 32]              70\n",
      "              ReLU-6           [-1, 35, 32, 32]               0\n",
      "         MaxPool2d-7           [-1, 35, 16, 16]               0\n",
      "            Conv2d-8           [-1, 92, 16, 16]          28,980\n",
      "       BatchNorm2d-9           [-1, 92, 16, 16]             184\n",
      "             ReLU-10           [-1, 92, 16, 16]               0\n",
      "           Conv2d-11           [-1, 74, 16, 16]          61,272\n",
      "      BatchNorm2d-12           [-1, 74, 16, 16]             148\n",
      "             ReLU-13           [-1, 74, 16, 16]               0\n",
      "        MaxPool2d-14             [-1, 74, 8, 8]               0\n",
      "           Conv2d-15            [-1, 167, 8, 8]         111,222\n",
      "      BatchNorm2d-16            [-1, 167, 8, 8]             334\n",
      "             ReLU-17            [-1, 167, 8, 8]               0\n",
      "           Conv2d-18            [-1, 126, 8, 8]         189,378\n",
      "      BatchNorm2d-19            [-1, 126, 8, 8]             252\n",
      "             ReLU-20            [-1, 126, 8, 8]               0\n",
      "        MaxPool2d-21            [-1, 126, 4, 4]               0\n",
      "           Conv2d-22            [-1, 270, 4, 4]         306,180\n",
      "      BatchNorm2d-23            [-1, 270, 4, 4]             540\n",
      "             ReLU-24            [-1, 270, 4, 4]               0\n",
      "           Conv2d-25            [-1, 236, 4, 4]         573,480\n",
      "      BatchNorm2d-26            [-1, 236, 4, 4]             472\n",
      "             ReLU-27            [-1, 236, 4, 4]               0\n",
      "        MaxPool2d-28            [-1, 236, 2, 2]               0\n",
      "           Conv2d-29            [-1, 151, 2, 2]         320,724\n",
      "      BatchNorm2d-30            [-1, 151, 2, 2]             302\n",
      "             ReLU-31            [-1, 151, 2, 2]               0\n",
      "           Conv2d-32              [-1, 3, 2, 2]           4,077\n",
      "      BatchNorm2d-33              [-1, 3, 2, 2]               6\n",
      "             ReLU-34              [-1, 3, 2, 2]               0\n",
      "           Linear-35                   [-1, 10]              40\n",
      "================================================================\n",
      "Total params: 1,605,573\n",
      "Trainable params: 1,605,573\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 3.09\n",
      "Params size (MB): 6.12\n",
      "Estimated Total Size (MB): 9.22\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(pruned_model, (3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de1a42f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
