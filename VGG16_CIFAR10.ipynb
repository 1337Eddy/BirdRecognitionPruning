{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c017511",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37bf145a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models, datasets\n",
    "from torch.autograd import Variable\n",
    "import shutil\n",
    "from torchsummary import summary\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a6f660",
   "metadata": {},
   "source": [
    "Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d4c730d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "torch.cuda.manual_seed(1337)\n",
    "\n",
    "batch_size = 100\n",
    "test_batch_size = 1000\n",
    "gamma = 0.001\n",
    "lr = 0.01\n",
    "prune_rate=0.9\n",
    "\n",
    "kwargs = {'num_workers': 16, 'pin_memory': True}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203a92f1",
   "metadata": {},
   "source": [
    "DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a58c5d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.CIFAR10('./data', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.Pad(4),\n",
    "                       transforms.RandomCrop(32),\n",
    "                       transforms.RandomHorizontalFlip(),\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                   ])),\n",
    "    batch_size=batch_size, shuffle=True, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.CIFAR10('./data', train=False, transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                   ])),\n",
    "    batch_size=test_batch_size, shuffle=True, **kwargs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8bbe0f",
   "metadata": {},
   "source": [
    "Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1a11852",
   "metadata": {},
   "outputs": [],
   "source": [
    "class sequential_model(nn.Module):\n",
    "    def __init__(self, layers=None):\n",
    "        super(sequential_model, self).__init__()\n",
    "        if layers == None:\n",
    "            layers = [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512]\n",
    "        num_classes = 10\n",
    "        self.feature = self.make_layers(layers)\n",
    "        self.classifier = nn.Linear(layers[-1], num_classes)\n",
    "    \n",
    "    def make_layers(self, structure):\n",
    "        layers = []\n",
    "        in_channels = 3\n",
    "        for v in structure:\n",
    "            if v == 'M':\n",
    "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "            else:\n",
    "                conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1, bias=False)\n",
    "                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n",
    "                in_channels = v\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.feature(x)\n",
    "        x = nn.AvgPool2d(2)(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        y = self.classifier(x)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec86493",
   "metadata": {},
   "source": [
    "Train Epoch method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bc310dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_scaling_factors(model):\n",
    "    sum_channel_scaling_factors = 0\n",
    "        \n",
    "    #sum absolute value from all channel scaling factors for sparsity\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, nn.BatchNorm2d):\n",
    "            sum_channel_scaling_factors += torch.sum(m.weight.data.abs())\n",
    "    return sum_channel_scaling_factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fcf83829",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, epoch, optimizer, data_loader=train_loader, sparsity=True):\n",
    "    model.train()\n",
    "    print(data_loader)\n",
    "    for idx, (data, target) in enumerate(data_loader):\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        \n",
    "        if sparsity:\n",
    "            sum_channel_scaling_factors = sum_scaling_factors(model)\n",
    "            loss = F.cross_entropy(output, target) + gamma * sum_channel_scaling_factors\n",
    "        else:\n",
    "            loss = F.cross_entropy(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "            \n",
    "        if idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.1f}%)]\\tLoss: {:.6f}'.format(\n",
    "            epoch, idx * len(data), len(data_loader.dataset),\n",
    "            100. * idx / len(data_loader), loss.data.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d7b31e",
   "metadata": {},
   "source": [
    "Validation Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eeeddf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns precision and loss of model\n",
    "def test(model, data_loader=test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in data_loader:\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "        data, target = Variable(data), Variable(target)        \n",
    "        output = model(data)\n",
    "        test_loss += F.cross_entropy(output, target, size_average=False).data.item()\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "        test_loss /= len(data_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.1f}%)\\n'.format(\n",
    "        test_loss, correct, len(data_loader.dataset),\n",
    "        100. * correct / len(data_loader.dataset)))\n",
    "    return (correct / float(len(data_loader.dataset)), test_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bc0761",
   "metadata": {},
   "source": [
    "Save Model Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6656403c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, filename='model_best'):\n",
    "    torch.save(state, filename + '_checkpoint.pth.tar')\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename + '_checkpoint.pth.tar', filename + '.pth.tar')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f892aa61",
   "metadata": {},
   "source": [
    "Train network method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc841441",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, epochs=10, sparsity=True, filename='best_model'):\n",
    "    \n",
    "    model.cuda()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    best_prec = 0.\n",
    "    for i in range(0, epochs):\n",
    "        train(model, i, optimizer, sparsity=sparsity)\n",
    "        prec, loss = test(model)\n",
    "        is_best = prec > best_prec\n",
    "        best_prec1 = max(prec, best_prec)\n",
    "        save_checkpoint({\n",
    "            'epoch': i + 1,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'best_prec1': best_prec,\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "        }, is_best, filename)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db21bd4",
   "metadata": {},
   "source": [
    "Load existing Model method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec19a675",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(checkpoint_path=\"checkpoint_sr.pth.tar\", model_path=\"model_best_sr.pth.tar\"):\n",
    "    model = sequential_model()\n",
    "    model.cuda()\n",
    "    if os.path.isfile(model_path):\n",
    "        print(\"=> loading checkpoint '{}'\".format(model_path))\n",
    "        checkpoint_path = torch.load(model_path)\n",
    "        best_prec1 = checkpoint_path['best_prec1']\n",
    "        model.load_state_dict(checkpoint_path['state_dict'])\n",
    "        print(\"=> loaded checkpoint '{}' (epoch {}) Prec1: {:f}\"\n",
    "              .format(model, checkpoint_path['epoch'], best_prec1))\n",
    "    else:\n",
    "        print(\"=> no checkpoint found at\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2690475",
   "metadata": {},
   "source": [
    "Select weak channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c609836",
   "metadata": {},
   "outputs": [],
   "source": [
    "def selectChannels(model, percent=0.2):\n",
    "    total = 0\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, nn.BatchNorm2d):\n",
    "            total += m.weight.data.shape[0]\n",
    "\n",
    "    bn = torch.zeros(total)\n",
    "    index = 0\n",
    "    print(\"Typ:\")\n",
    "    print(type(model.modules()))\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, nn.BatchNorm2d):\n",
    "            size = m.weight.data.shape[0]\n",
    "            bn[index:(index+size)] = m.weight.data.abs().clone()\n",
    "            index += size\n",
    "\n",
    "    y, i = torch.sort(bn)\n",
    "    thre_index = int(total * percent)\n",
    "    thre = y[thre_index]\n",
    "\n",
    "    pruned = 0\n",
    "    cfg = []\n",
    "    cfg_mask = []\n",
    "    for k, m in enumerate(model.modules()):\n",
    "        if isinstance(m, nn.BatchNorm2d):\n",
    "            weight_copy = m.weight.data.clone()\n",
    "            print(type(weight_copy.abs().gt(thre).float()))\n",
    "            #mask is a matrix in which 1 marks the channels which are kept and 0 marks the pruned channels\n",
    "            mask = weight_copy.abs().gt(thre).float().cuda()          \n",
    "            #pruned is the number of all pruned channels \n",
    "            pruned = pruned + mask.shape[0] - torch.sum(mask)\n",
    "            m.weight.data.mul_(mask)\n",
    "            m.bias.data.mul_(mask)\n",
    "            cfg.append(int(torch.sum(mask)))\n",
    "            cfg_mask.append(mask.clone())\n",
    "            print('layer index: {:d} \\t total channel: {:d} \\t remaining channel: {:d}'.\n",
    "                format(k, mask.shape[0], int(torch.sum(mask))))\n",
    "        elif isinstance(m, nn.MaxPool2d):\n",
    "            cfg.append('M')\n",
    "    return cfg, cfg_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16e172a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Takes a smaller network structure in which the model is transfered.\n",
    "cfg_mask marks all parameters over model which are transfered or dropped\n",
    "\"\"\"\n",
    "def transfer_params(cfg, cfg_mask, model):\n",
    "    filtered_cfg = []\n",
    "    #remove all layers with zero or one channel\n",
    "    for elem in cfg:\n",
    "        if type(elem) is int and elem > 1:\n",
    "            filtered_cfg.append(elem)\n",
    "        elif type(elem) is str:\n",
    "            filtered_cfg.append(elem)\n",
    "    cfg = filtered_cfg\n",
    "    \n",
    "    \n",
    "    newmodel = sequential_model(layers=cfg)\n",
    "    newmodel.cuda() \n",
    "\n",
    "    layer_id_in_cfg = 0\n",
    "    start_mask = torch.ones(3)\n",
    "    end_mask = cfg_mask[layer_id_in_cfg]\n",
    "    skip_linear = False\n",
    "    \n",
    "    parameters = newmodel.modules()\n",
    "    layer = next(parameters)\n",
    "    layer = next(parameters)\n",
    "    layer = next(parameters)\n",
    "    skip_next = 0\n",
    "    for m0 in model.modules(): \n",
    "        if isinstance(layer, nn.MaxPool2d):\n",
    "            layer = next(parameters)\n",
    "        if skip_next > 0:\n",
    "            skip_next -= 1\n",
    "            continue\n",
    "        if isinstance(m0, nn.BatchNorm2d):\n",
    "            idx1 = np.squeeze(np.argwhere(np.asarray(end_mask.cpu().numpy())))\n",
    "            layer.weight.data = m0.weight.data[idx1].clone()\n",
    "            layer.bias.data = m0.bias.data[idx1].clone()\n",
    "            layer.running_mean = m0.running_mean[idx1].clone()\n",
    "            layer.running_var = m0.running_var[idx1].clone()\n",
    "            layer_id_in_cfg += 1\n",
    "            start_mask = end_mask.clone()\n",
    "            if layer_id_in_cfg < len(cfg_mask):  # do not change in Final FC\n",
    "                end_mask = cfg_mask[layer_id_in_cfg]\n",
    "            layer = next(parameters)\n",
    "        elif isinstance(m0, nn.Conv2d):\n",
    "            idx0 = np.squeeze(np.argwhere(np.asarray(start_mask.cpu().numpy())))\n",
    "            idx1 = np.squeeze(np.argwhere(np.asarray(end_mask.cpu().numpy())))\n",
    "            if np.size(idx1) <= 1: \n",
    "                skip_next = 2\n",
    "                layer_id_in_cfg += 1\n",
    "                if layer_id_in_cfg < len(cfg_mask):  # do not change in Final FC\n",
    "                    end_mask = cfg_mask[layer_id_in_cfg]\n",
    "                continue\n",
    "            print('In shape: {:d} Out shape:{:d}'.format(idx0.shape[0], idx1.shape[0]))\n",
    "            w = m0.weight.data[:, idx0, :, :].clone()\n",
    "            w = w[idx1, :, :, :].clone()\n",
    "            layer.weight.data = w.clone()\n",
    "            layer = next(parameters)\n",
    "            # m1.bias.data = m0.bias.data[idx1].clone()\n",
    "        elif isinstance(m0, nn.Linear):\n",
    "            idx0 = np.squeeze(np.argwhere(np.asarray(start_mask.cpu().numpy())))\n",
    "            layer.weight.data = m0.weight.data[:, idx0].clone()      \n",
    "            #layer = next(parameters)\n",
    "        elif isinstance(m0, nn.ReLU):\n",
    "            layer = next(parameters)\n",
    "        \n",
    "    return newmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b64546cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_model(model, percent=0.3):\n",
    "    cfg, cfg_mask = selectChannels(model, percent)\n",
    "    print(cfg)\n",
    "    prune_model = transfer_params(cfg, cfg_mask, model)\n",
    "    torch.save({'cfg': cfg, 'state_dict': prune_model.state_dict()}, f='pruned_model.pt')\n",
    "    return prune_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c664c7a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7f7352e45ee0>\n",
      "Train Epoch: 0 [0/50000 (0.0%)]\tLoss: 5.300352\n",
      "Train Epoch: 0 [10000/50000 (20.0%)]\tLoss: 4.859546\n",
      "Train Epoch: 0 [20000/50000 (40.0%)]\tLoss: 4.595735\n",
      "Train Epoch: 0 [30000/50000 (60.0%)]\tLoss: 4.287578\n",
      "Train Epoch: 0 [40000/50000 (80.0%)]\tLoss: 4.242346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eddy/Programme/anaconda3/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.1287, Accuracy: 5320/10000 (53.2%)\n",
      "\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f7352e45ee0>\n",
      "Train Epoch: 1 [0/50000 (0.0%)]\tLoss: 3.854077\n",
      "Train Epoch: 1 [10000/50000 (20.0%)]\tLoss: 3.840196\n",
      "Train Epoch: 1 [20000/50000 (40.0%)]\tLoss: 3.783875\n",
      "Train Epoch: 1 [30000/50000 (60.0%)]\tLoss: 3.722288\n",
      "Train Epoch: 1 [40000/50000 (80.0%)]\tLoss: 3.820740\n",
      "\n",
      "Test set: Average loss: 0.0984, Accuracy: 6558/10000 (65.6%)\n",
      "\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f7352e45ee0>\n",
      "Train Epoch: 2 [0/50000 (0.0%)]\tLoss: 3.696454\n",
      "Train Epoch: 2 [10000/50000 (20.0%)]\tLoss: 3.618945\n",
      "Train Epoch: 2 [20000/50000 (40.0%)]\tLoss: 3.643742\n",
      "Train Epoch: 2 [30000/50000 (60.0%)]\tLoss: 3.549144\n",
      "Train Epoch: 2 [40000/50000 (80.0%)]\tLoss: 3.516099\n",
      "\n",
      "Test set: Average loss: 0.0774, Accuracy: 7406/10000 (74.1%)\n",
      "\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f7352e45ee0>\n",
      "Train Epoch: 3 [0/50000 (0.0%)]\tLoss: 3.572057\n",
      "Train Epoch: 3 [10000/50000 (20.0%)]\tLoss: 3.327058\n",
      "Train Epoch: 3 [20000/50000 (40.0%)]\tLoss: 3.463232\n",
      "Train Epoch: 3 [30000/50000 (60.0%)]\tLoss: 3.536172\n",
      "Train Epoch: 3 [40000/50000 (80.0%)]\tLoss: 3.549736\n",
      "\n",
      "Test set: Average loss: 0.0756, Accuracy: 7448/10000 (74.5%)\n",
      "\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f7352e45ee0>\n",
      "Train Epoch: 4 [0/50000 (0.0%)]\tLoss: 3.346048\n",
      "Train Epoch: 4 [10000/50000 (20.0%)]\tLoss: 3.333418\n",
      "Train Epoch: 4 [20000/50000 (40.0%)]\tLoss: 3.556769\n",
      "Train Epoch: 4 [30000/50000 (60.0%)]\tLoss: 3.347742\n",
      "Train Epoch: 4 [40000/50000 (80.0%)]\tLoss: 3.402766\n",
      "\n",
      "Test set: Average loss: 0.0588, Accuracy: 7977/10000 (79.8%)\n",
      "\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f7352e45ee0>\n",
      "Train Epoch: 5 [0/50000 (0.0%)]\tLoss: 3.376482\n",
      "Train Epoch: 5 [10000/50000 (20.0%)]\tLoss: 3.522112\n",
      "Train Epoch: 5 [20000/50000 (40.0%)]\tLoss: 3.432272\n",
      "Train Epoch: 5 [30000/50000 (60.0%)]\tLoss: 3.282859\n",
      "Train Epoch: 5 [40000/50000 (80.0%)]\tLoss: 3.476357\n",
      "\n",
      "Test set: Average loss: 0.0598, Accuracy: 7965/10000 (79.7%)\n",
      "\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f7352e45ee0>\n",
      "Train Epoch: 6 [0/50000 (0.0%)]\tLoss: 3.271696\n",
      "Train Epoch: 6 [10000/50000 (20.0%)]\tLoss: 3.168054\n",
      "Train Epoch: 6 [20000/50000 (40.0%)]\tLoss: 3.383941\n",
      "Train Epoch: 6 [30000/50000 (60.0%)]\tLoss: 3.487520\n",
      "Train Epoch: 6 [40000/50000 (80.0%)]\tLoss: 3.346768\n",
      "\n",
      "Test set: Average loss: 0.0484, Accuracy: 8365/10000 (83.7%)\n",
      "\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f7352e45ee0>\n",
      "Train Epoch: 7 [0/50000 (0.0%)]\tLoss: 3.443779\n",
      "Train Epoch: 7 [10000/50000 (20.0%)]\tLoss: 3.229661\n",
      "Train Epoch: 7 [20000/50000 (40.0%)]\tLoss: 3.464520\n",
      "Train Epoch: 7 [30000/50000 (60.0%)]\tLoss: 3.399137\n",
      "Train Epoch: 7 [40000/50000 (80.0%)]\tLoss: 3.370882\n",
      "\n",
      "Test set: Average loss: 0.0438, Accuracy: 8382/10000 (83.8%)\n",
      "\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f7352e45ee0>\n",
      "Train Epoch: 8 [0/50000 (0.0%)]\tLoss: 3.428910\n",
      "Train Epoch: 8 [10000/50000 (20.0%)]\tLoss: 3.248703\n",
      "Train Epoch: 8 [20000/50000 (40.0%)]\tLoss: 3.433930\n",
      "Train Epoch: 8 [30000/50000 (60.0%)]\tLoss: 3.278090\n",
      "Train Epoch: 8 [40000/50000 (80.0%)]\tLoss: 3.361110\n",
      "\n",
      "Test set: Average loss: 0.0431, Accuracy: 8467/10000 (84.7%)\n",
      "\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f7352e45ee0>\n",
      "Train Epoch: 9 [0/50000 (0.0%)]\tLoss: 3.133504\n",
      "Train Epoch: 9 [10000/50000 (20.0%)]\tLoss: 3.260145\n",
      "Train Epoch: 9 [20000/50000 (40.0%)]\tLoss: 3.216461\n",
      "Train Epoch: 9 [30000/50000 (60.0%)]\tLoss: 3.295173\n",
      "Train Epoch: 9 [40000/50000 (80.0%)]\tLoss: 3.383753\n",
      "\n",
      "Test set: Average loss: 0.0473, Accuracy: 8439/10000 (84.4%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_sparsity = train_model(sequential_model(), epochs=10, sparsity=True, filename='epochs10_sparsity')\n",
    "#model = train_model(sequential_model(), epochs=10, sparsity=False, filename='epochs10_no_sparsity')\n",
    "#model = load_model(checkpoint_path=\"epochs10_sparsity.pth.tar\", model_path=\"epochs10_sparsity_checkpoint.pth.tar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e9f76e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Typ:\n",
      "<class 'generator'>\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 3 \t total channel: 64 \t remaining channel: 58\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 6 \t total channel: 64 \t remaining channel: 64\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 10 \t total channel: 128 \t remaining channel: 128\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 13 \t total channel: 128 \t remaining channel: 128\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 17 \t total channel: 256 \t remaining channel: 256\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 20 \t total channel: 256 \t remaining channel: 254\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 24 \t total channel: 512 \t remaining channel: 505\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 27 \t total channel: 512 \t remaining channel: 511\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 31 \t total channel: 512 \t remaining channel: 508\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 34 \t total channel: 512 \t remaining channel: 384\n",
      "[58, 64, 'M', 128, 128, 'M', 256, 254, 'M', 505, 511, 'M', 508, 384]\n",
      "In shape: 3 Out shape:58\n",
      "In shape: 58 Out shape:64\n",
      "In shape: 64 Out shape:128\n",
      "In shape: 128 Out shape:128\n",
      "In shape: 128 Out shape:256\n",
      "In shape: 256 Out shape:254\n",
      "In shape: 254 Out shape:505\n",
      "In shape: 505 Out shape:511\n",
      "In shape: 511 Out shape:508\n",
      "In shape: 508 Out shape:384\n",
      "\n",
      "Test set: Average loss: 0.0472, Accuracy: 8373/10000 (83.7%)\n",
      "\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f7352e45ee0>\n",
      "Train Epoch: 0 [0/50000 (0.0%)]\tLoss: 3.199608\n",
      "Train Epoch: 0 [10000/50000 (20.0%)]\tLoss: 3.159832\n",
      "Train Epoch: 0 [20000/50000 (40.0%)]\tLoss: 3.278534\n",
      "Train Epoch: 0 [30000/50000 (60.0%)]\tLoss: 3.168948\n",
      "Train Epoch: 0 [40000/50000 (80.0%)]\tLoss: 3.099651\n",
      "\n",
      "Test set: Average loss: 0.0501, Accuracy: 8387/10000 (83.9%)\n",
      "\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f7352e45ee0>\n",
      "Train Epoch: 1 [0/50000 (0.0%)]\tLoss: 3.133091\n",
      "Train Epoch: 1 [10000/50000 (20.0%)]\tLoss: 2.962137\n",
      "Train Epoch: 1 [20000/50000 (40.0%)]\tLoss: 3.174865\n",
      "Train Epoch: 1 [30000/50000 (60.0%)]\tLoss: 3.054279\n",
      "Train Epoch: 1 [40000/50000 (80.0%)]\tLoss: 3.083988\n",
      "\n",
      "Test set: Average loss: 0.0456, Accuracy: 8601/10000 (86.0%)\n",
      "\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f7352e45ee0>\n",
      "Train Epoch: 2 [0/50000 (0.0%)]\tLoss: 3.111778\n",
      "Train Epoch: 2 [10000/50000 (20.0%)]\tLoss: 2.979625\n",
      "Train Epoch: 2 [20000/50000 (40.0%)]\tLoss: 2.990445\n",
      "Train Epoch: 2 [30000/50000 (60.0%)]\tLoss: 3.012664\n",
      "Train Epoch: 2 [40000/50000 (80.0%)]\tLoss: 3.124612\n",
      "\n",
      "Test set: Average loss: 0.0382, Accuracy: 8752/10000 (87.5%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0399, Accuracy: 8752/10000 (87.5%)\n",
      "\n",
      "Typ:\n",
      "<class 'generator'>\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 3 \t total channel: 64 \t remaining channel: 57\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 6 \t total channel: 64 \t remaining channel: 64\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 10 \t total channel: 128 \t remaining channel: 128\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 13 \t total channel: 128 \t remaining channel: 127\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 17 \t total channel: 256 \t remaining channel: 256\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 20 \t total channel: 256 \t remaining channel: 254\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 24 \t total channel: 512 \t remaining channel: 497\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 27 \t total channel: 512 \t remaining channel: 507\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 31 \t total channel: 512 \t remaining channel: 503\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 34 \t total channel: 512 \t remaining channel: 256\n",
      "[57, 64, 'M', 128, 127, 'M', 256, 254, 'M', 497, 507, 'M', 503, 256]\n",
      "In shape: 3 Out shape:57\n",
      "In shape: 57 Out shape:64\n",
      "In shape: 64 Out shape:128\n",
      "In shape: 128 Out shape:127\n",
      "In shape: 127 Out shape:256\n",
      "In shape: 256 Out shape:254\n",
      "In shape: 254 Out shape:497\n",
      "In shape: 497 Out shape:507\n",
      "In shape: 507 Out shape:503\n",
      "In shape: 503 Out shape:256\n",
      "\n",
      "Test set: Average loss: 0.0520, Accuracy: 8374/10000 (83.7%)\n",
      "\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f7352e45ee0>\n",
      "Train Epoch: 0 [0/50000 (0.0%)]\tLoss: 3.171515\n",
      "Train Epoch: 0 [10000/50000 (20.0%)]\tLoss: 3.249307\n",
      "Train Epoch: 0 [20000/50000 (40.0%)]\tLoss: 3.114651\n",
      "Train Epoch: 0 [30000/50000 (60.0%)]\tLoss: 3.025013\n",
      "Train Epoch: 0 [40000/50000 (80.0%)]\tLoss: 3.170483\n",
      "\n",
      "Test set: Average loss: 0.0534, Accuracy: 8366/10000 (83.7%)\n",
      "\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f7352e45ee0>\n",
      "Train Epoch: 1 [0/50000 (0.0%)]\tLoss: 3.008768\n",
      "Train Epoch: 1 [10000/50000 (20.0%)]\tLoss: 3.112098\n",
      "Train Epoch: 1 [20000/50000 (40.0%)]\tLoss: 3.152210\n",
      "Train Epoch: 1 [30000/50000 (60.0%)]\tLoss: 2.932548\n",
      "Train Epoch: 1 [40000/50000 (80.0%)]\tLoss: 3.192108\n",
      "\n",
      "Test set: Average loss: 0.0392, Accuracy: 8540/10000 (85.4%)\n",
      "\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f7352e45ee0>\n",
      "Train Epoch: 2 [0/50000 (0.0%)]\tLoss: 2.983168\n",
      "Train Epoch: 2 [10000/50000 (20.0%)]\tLoss: 2.997965\n",
      "Train Epoch: 2 [20000/50000 (40.0%)]\tLoss: 2.997031\n",
      "Train Epoch: 2 [30000/50000 (60.0%)]\tLoss: 2.987918\n",
      "Train Epoch: 2 [40000/50000 (80.0%)]\tLoss: 3.004602\n",
      "\n",
      "Test set: Average loss: 0.0399, Accuracy: 8708/10000 (87.1%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0376, Accuracy: 8708/10000 (87.1%)\n",
      "\n",
      "Typ:\n",
      "<class 'generator'>\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 3 \t total channel: 64 \t remaining channel: 54\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 6 \t total channel: 64 \t remaining channel: 63\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 10 \t total channel: 128 \t remaining channel: 128\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 13 \t total channel: 128 \t remaining channel: 127\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 17 \t total channel: 256 \t remaining channel: 255\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 20 \t total channel: 256 \t remaining channel: 254\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 24 \t total channel: 512 \t remaining channel: 489\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 27 \t total channel: 512 \t remaining channel: 495\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 31 \t total channel: 512 \t remaining channel: 493\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 34 \t total channel: 512 \t remaining channel: 144\n",
      "[54, 63, 'M', 128, 127, 'M', 255, 254, 'M', 489, 495, 'M', 493, 144]\n",
      "In shape: 3 Out shape:54\n",
      "In shape: 54 Out shape:63\n",
      "In shape: 63 Out shape:128\n",
      "In shape: 128 Out shape:127\n",
      "In shape: 127 Out shape:255\n",
      "In shape: 255 Out shape:254\n",
      "In shape: 254 Out shape:489\n",
      "In shape: 489 Out shape:495\n",
      "In shape: 495 Out shape:493\n",
      "In shape: 493 Out shape:144\n",
      "\n",
      "Test set: Average loss: 0.0512, Accuracy: 8382/10000 (83.8%)\n",
      "\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f7352e45ee0>\n",
      "Train Epoch: 0 [0/50000 (0.0%)]\tLoss: 3.000166\n",
      "Train Epoch: 0 [10000/50000 (20.0%)]\tLoss: 3.173093\n",
      "Train Epoch: 0 [20000/50000 (40.0%)]\tLoss: 3.090618\n",
      "Train Epoch: 0 [30000/50000 (60.0%)]\tLoss: 3.045158\n",
      "Train Epoch: 0 [40000/50000 (80.0%)]\tLoss: 3.030365\n",
      "\n",
      "Test set: Average loss: 0.0456, Accuracy: 8511/10000 (85.1%)\n",
      "\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f7352e45ee0>\n",
      "Train Epoch: 1 [0/50000 (0.0%)]\tLoss: 3.078410\n",
      "Train Epoch: 1 [10000/50000 (20.0%)]\tLoss: 2.844920\n",
      "Train Epoch: 1 [20000/50000 (40.0%)]\tLoss: 2.973676\n",
      "Train Epoch: 1 [30000/50000 (60.0%)]\tLoss: 3.062007\n",
      "Train Epoch: 1 [40000/50000 (80.0%)]\tLoss: 3.080426\n",
      "\n",
      "Test set: Average loss: 0.0524, Accuracy: 8403/10000 (84.0%)\n",
      "\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f7352e45ee0>\n",
      "Train Epoch: 2 [0/50000 (0.0%)]\tLoss: 2.890411\n",
      "Train Epoch: 2 [10000/50000 (20.0%)]\tLoss: 3.116969\n",
      "Train Epoch: 2 [20000/50000 (40.0%)]\tLoss: 2.875039\n",
      "Train Epoch: 2 [30000/50000 (60.0%)]\tLoss: 2.919554\n",
      "Train Epoch: 2 [40000/50000 (80.0%)]\tLoss: 2.902323\n",
      "\n",
      "Test set: Average loss: 0.0444, Accuracy: 8622/10000 (86.2%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0426, Accuracy: 8622/10000 (86.2%)\n",
      "\n",
      "Typ:\n",
      "<class 'generator'>\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 3 \t total channel: 64 \t remaining channel: 50\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 6 \t total channel: 64 \t remaining channel: 63\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 10 \t total channel: 128 \t remaining channel: 128\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 13 \t total channel: 128 \t remaining channel: 127\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 17 \t total channel: 256 \t remaining channel: 253\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 20 \t total channel: 256 \t remaining channel: 249\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 24 \t total channel: 512 \t remaining channel: 468\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 27 \t total channel: 512 \t remaining channel: 462\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 31 \t total channel: 512 \t remaining channel: 459\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 34 \t total channel: 512 \t remaining channel: 96\n",
      "[50, 63, 'M', 128, 127, 'M', 253, 249, 'M', 468, 462, 'M', 459, 96]\n",
      "In shape: 3 Out shape:50\n",
      "In shape: 50 Out shape:63\n",
      "In shape: 63 Out shape:128\n",
      "In shape: 128 Out shape:127\n",
      "In shape: 127 Out shape:253\n",
      "In shape: 253 Out shape:249\n",
      "In shape: 249 Out shape:468\n",
      "In shape: 468 Out shape:462\n",
      "In shape: 462 Out shape:459\n",
      "In shape: 459 Out shape:96\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0507, Accuracy: 8357/10000 (83.6%)\n",
      "\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f7352e45ee0>\n",
      "Train Epoch: 0 [0/50000 (0.0%)]\tLoss: 3.041523\n",
      "Train Epoch: 0 [10000/50000 (20.0%)]\tLoss: 3.020796\n",
      "Train Epoch: 0 [20000/50000 (40.0%)]\tLoss: 3.073426\n",
      "Train Epoch: 0 [30000/50000 (60.0%)]\tLoss: 2.930467\n",
      "Train Epoch: 0 [40000/50000 (80.0%)]\tLoss: 2.910487\n",
      "\n",
      "Test set: Average loss: 0.0390, Accuracy: 8639/10000 (86.4%)\n",
      "\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f7352e45ee0>\n",
      "Train Epoch: 1 [0/50000 (0.0%)]\tLoss: 2.963043\n",
      "Train Epoch: 1 [10000/50000 (20.0%)]\tLoss: 2.983863\n",
      "Train Epoch: 1 [20000/50000 (40.0%)]\tLoss: 2.914312\n",
      "Train Epoch: 1 [30000/50000 (60.0%)]\tLoss: 2.951758\n",
      "Train Epoch: 1 [40000/50000 (80.0%)]\tLoss: 2.868842\n",
      "\n",
      "Test set: Average loss: 0.0476, Accuracy: 8583/10000 (85.8%)\n",
      "\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f7352e45ee0>\n",
      "Train Epoch: 2 [0/50000 (0.0%)]\tLoss: 2.881527\n",
      "Train Epoch: 2 [10000/50000 (20.0%)]\tLoss: 2.921322\n",
      "Train Epoch: 2 [20000/50000 (40.0%)]\tLoss: 2.832723\n",
      "Train Epoch: 2 [30000/50000 (60.0%)]\tLoss: 2.874414\n",
      "Train Epoch: 2 [40000/50000 (80.0%)]\tLoss: 2.885393\n",
      "\n",
      "Test set: Average loss: 0.0461, Accuracy: 8641/10000 (86.4%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0379, Accuracy: 8641/10000 (86.4%)\n",
      "\n",
      "Typ:\n",
      "<class 'generator'>\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 3 \t total channel: 64 \t remaining channel: 43\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 6 \t total channel: 64 \t remaining channel: 62\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 10 \t total channel: 128 \t remaining channel: 128\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 13 \t total channel: 128 \t remaining channel: 126\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 17 \t total channel: 256 \t remaining channel: 248\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 20 \t total channel: 256 \t remaining channel: 243\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 24 \t total channel: 512 \t remaining channel: 446\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 27 \t total channel: 512 \t remaining channel: 433\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 31 \t total channel: 512 \t remaining channel: 415\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 34 \t total channel: 512 \t remaining channel: 63\n",
      "[43, 62, 'M', 128, 126, 'M', 248, 243, 'M', 446, 433, 'M', 415, 63]\n",
      "In shape: 3 Out shape:43\n",
      "In shape: 43 Out shape:62\n",
      "In shape: 62 Out shape:128\n",
      "In shape: 128 Out shape:126\n",
      "In shape: 126 Out shape:248\n",
      "In shape: 248 Out shape:243\n",
      "In shape: 243 Out shape:446\n",
      "In shape: 446 Out shape:433\n",
      "In shape: 433 Out shape:415\n",
      "In shape: 415 Out shape:63\n",
      "\n",
      "Test set: Average loss: 0.0585, Accuracy: 8208/10000 (82.1%)\n",
      "\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f7352e45ee0>\n",
      "Train Epoch: 0 [0/50000 (0.0%)]\tLoss: 2.973325\n",
      "Train Epoch: 0 [10000/50000 (20.0%)]\tLoss: 3.001095\n",
      "Train Epoch: 0 [20000/50000 (40.0%)]\tLoss: 3.027111\n",
      "Train Epoch: 0 [30000/50000 (60.0%)]\tLoss: 2.979798\n",
      "Train Epoch: 0 [40000/50000 (80.0%)]\tLoss: 2.981377\n",
      "\n",
      "Test set: Average loss: 0.0370, Accuracy: 8661/10000 (86.6%)\n",
      "\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f7352e45ee0>\n",
      "Train Epoch: 1 [0/50000 (0.0%)]\tLoss: 2.810678\n",
      "Train Epoch: 1 [10000/50000 (20.0%)]\tLoss: 3.044304\n",
      "Train Epoch: 1 [20000/50000 (40.0%)]\tLoss: 2.879699\n",
      "Train Epoch: 1 [30000/50000 (60.0%)]\tLoss: 2.903196\n",
      "Train Epoch: 1 [40000/50000 (80.0%)]\tLoss: 2.964968\n",
      "\n",
      "Test set: Average loss: 0.0434, Accuracy: 8511/10000 (85.1%)\n",
      "\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f7352e45ee0>\n",
      "Train Epoch: 2 [0/50000 (0.0%)]\tLoss: 2.939013\n",
      "Train Epoch: 2 [10000/50000 (20.0%)]\tLoss: 2.881512\n",
      "Train Epoch: 2 [20000/50000 (40.0%)]\tLoss: 3.039100\n",
      "Train Epoch: 2 [30000/50000 (60.0%)]\tLoss: 2.825167\n",
      "Train Epoch: 2 [40000/50000 (80.0%)]\tLoss: 2.927867\n",
      "\n",
      "Test set: Average loss: 0.0498, Accuracy: 8414/10000 (84.1%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0527, Accuracy: 8414/10000 (84.1%)\n",
      "\n",
      "Typ:\n",
      "<class 'generator'>\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 3 \t total channel: 64 \t remaining channel: 39\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 6 \t total channel: 64 \t remaining channel: 62\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 10 \t total channel: 128 \t remaining channel: 126\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 13 \t total channel: 128 \t remaining channel: 125\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 17 \t total channel: 256 \t remaining channel: 241\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 20 \t total channel: 256 \t remaining channel: 230\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 24 \t total channel: 512 \t remaining channel: 422\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 27 \t total channel: 512 \t remaining channel: 398\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 31 \t total channel: 512 \t remaining channel: 371\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 34 \t total channel: 512 \t remaining channel: 46\n",
      "[39, 62, 'M', 126, 125, 'M', 241, 230, 'M', 422, 398, 'M', 371, 46]\n",
      "In shape: 3 Out shape:39\n",
      "In shape: 39 Out shape:62\n",
      "In shape: 62 Out shape:126\n",
      "In shape: 126 Out shape:125\n",
      "In shape: 125 Out shape:241\n",
      "In shape: 241 Out shape:230\n",
      "In shape: 230 Out shape:422\n",
      "In shape: 422 Out shape:398\n",
      "In shape: 398 Out shape:371\n",
      "In shape: 371 Out shape:46\n",
      "\n",
      "Test set: Average loss: 0.0687, Accuracy: 7929/10000 (79.3%)\n",
      "\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f7352e45ee0>\n",
      "Train Epoch: 0 [0/50000 (0.0%)]\tLoss: 2.918420\n",
      "Train Epoch: 0 [10000/50000 (20.0%)]\tLoss: 2.853011\n",
      "Train Epoch: 0 [20000/50000 (40.0%)]\tLoss: 2.757375\n",
      "Train Epoch: 0 [30000/50000 (60.0%)]\tLoss: 2.845862\n",
      "Train Epoch: 0 [40000/50000 (80.0%)]\tLoss: 2.678285\n",
      "\n",
      "Test set: Average loss: 0.0465, Accuracy: 8558/10000 (85.6%)\n",
      "\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f7352e45ee0>\n",
      "Train Epoch: 1 [0/50000 (0.0%)]\tLoss: 2.884209\n",
      "Train Epoch: 1 [10000/50000 (20.0%)]\tLoss: 2.765478\n",
      "Train Epoch: 1 [20000/50000 (40.0%)]\tLoss: 2.889810\n",
      "Train Epoch: 1 [30000/50000 (60.0%)]\tLoss: 2.818063\n",
      "Train Epoch: 1 [40000/50000 (80.0%)]\tLoss: 2.816201\n",
      "\n",
      "Test set: Average loss: 0.0450, Accuracy: 8598/10000 (86.0%)\n",
      "\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f7352e45ee0>\n",
      "Train Epoch: 2 [0/50000 (0.0%)]\tLoss: 2.716107\n",
      "Train Epoch: 2 [10000/50000 (20.0%)]\tLoss: 2.731217\n",
      "Train Epoch: 2 [20000/50000 (40.0%)]\tLoss: 2.881514\n",
      "Train Epoch: 2 [30000/50000 (60.0%)]\tLoss: 2.749229\n",
      "Train Epoch: 2 [40000/50000 (80.0%)]\tLoss: 2.849809\n",
      "\n",
      "Test set: Average loss: 0.0438, Accuracy: 8669/10000 (86.7%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0412, Accuracy: 8669/10000 (86.7%)\n",
      "\n",
      "Typ:\n",
      "<class 'generator'>\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 3 \t total channel: 64 \t remaining channel: 34\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 6 \t total channel: 64 \t remaining channel: 60\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 10 \t total channel: 128 \t remaining channel: 126\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 13 \t total channel: 128 \t remaining channel: 119\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 17 \t total channel: 256 \t remaining channel: 231\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 20 \t total channel: 256 \t remaining channel: 218\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 24 \t total channel: 512 \t remaining channel: 394\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 27 \t total channel: 512 \t remaining channel: 365\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 31 \t total channel: 512 \t remaining channel: 328\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 34 \t total channel: 512 \t remaining channel: 38\n",
      "[34, 60, 'M', 126, 119, 'M', 231, 218, 'M', 394, 365, 'M', 328, 38]\n",
      "In shape: 3 Out shape:34\n",
      "In shape: 34 Out shape:60\n",
      "In shape: 60 Out shape:126\n",
      "In shape: 126 Out shape:119\n",
      "In shape: 119 Out shape:231\n",
      "In shape: 231 Out shape:218\n",
      "In shape: 218 Out shape:394\n",
      "In shape: 394 Out shape:365\n",
      "In shape: 365 Out shape:328\n",
      "In shape: 328 Out shape:38\n",
      "\n",
      "Test set: Average loss: 0.1038, Accuracy: 6710/10000 (67.1%)\n",
      "\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f7352e45ee0>\n",
      "Train Epoch: 0 [0/50000 (0.0%)]\tLoss: 2.946424\n",
      "Train Epoch: 0 [10000/50000 (20.0%)]\tLoss: 2.645822\n",
      "Train Epoch: 0 [20000/50000 (40.0%)]\tLoss: 2.738436\n",
      "Train Epoch: 0 [30000/50000 (60.0%)]\tLoss: 2.759036\n",
      "Train Epoch: 0 [40000/50000 (80.0%)]\tLoss: 2.773988\n",
      "\n",
      "Test set: Average loss: 0.0422, Accuracy: 8555/10000 (85.6%)\n",
      "\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f7352e45ee0>\n",
      "Train Epoch: 1 [0/50000 (0.0%)]\tLoss: 2.671011\n",
      "Train Epoch: 1 [10000/50000 (20.0%)]\tLoss: 2.815668\n",
      "Train Epoch: 1 [20000/50000 (40.0%)]\tLoss: 2.763423\n",
      "Train Epoch: 1 [30000/50000 (60.0%)]\tLoss: 2.661049\n",
      "Train Epoch: 1 [40000/50000 (80.0%)]\tLoss: 2.674212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0514, Accuracy: 8360/10000 (83.6%)\n",
      "\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f7352e45ee0>\n",
      "Train Epoch: 2 [0/50000 (0.0%)]\tLoss: 2.591128\n",
      "Train Epoch: 2 [10000/50000 (20.0%)]\tLoss: 2.630425\n",
      "Train Epoch: 2 [20000/50000 (40.0%)]\tLoss: 2.661383\n",
      "Train Epoch: 2 [30000/50000 (60.0%)]\tLoss: 2.610324\n",
      "Train Epoch: 2 [40000/50000 (80.0%)]\tLoss: 2.776558\n",
      "\n",
      "Test set: Average loss: 0.0343, Accuracy: 8743/10000 (87.4%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0383, Accuracy: 8743/10000 (87.4%)\n",
      "\n",
      "Typ:\n",
      "<class 'generator'>\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 3 \t total channel: 64 \t remaining channel: 28\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 6 \t total channel: 64 \t remaining channel: 58\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 10 \t total channel: 128 \t remaining channel: 121\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 13 \t total channel: 128 \t remaining channel: 117\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 17 \t total channel: 256 \t remaining channel: 222\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 20 \t total channel: 256 \t remaining channel: 210\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 24 \t total channel: 512 \t remaining channel: 366\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 27 \t total channel: 512 \t remaining channel: 326\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 31 \t total channel: 512 \t remaining channel: 287\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 34 \t total channel: 512 \t remaining channel: 31\n",
      "[28, 58, 'M', 121, 117, 'M', 222, 210, 'M', 366, 326, 'M', 287, 31]\n",
      "In shape: 3 Out shape:28\n",
      "In shape: 28 Out shape:58\n",
      "In shape: 58 Out shape:121\n",
      "In shape: 121 Out shape:117\n",
      "In shape: 117 Out shape:222\n",
      "In shape: 222 Out shape:210\n",
      "In shape: 210 Out shape:366\n",
      "In shape: 366 Out shape:326\n",
      "In shape: 326 Out shape:287\n",
      "In shape: 287 Out shape:31\n",
      "\n",
      "Test set: Average loss: 0.1209, Accuracy: 5752/10000 (57.5%)\n",
      "\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f7352e45ee0>\n",
      "Train Epoch: 0 [0/50000 (0.0%)]\tLoss: 2.730250\n",
      "Train Epoch: 0 [10000/50000 (20.0%)]\tLoss: 2.752807\n",
      "Train Epoch: 0 [20000/50000 (40.0%)]\tLoss: 2.596661\n",
      "Train Epoch: 0 [30000/50000 (60.0%)]\tLoss: 2.613915\n",
      "Train Epoch: 0 [40000/50000 (80.0%)]\tLoss: 2.675101\n",
      "\n",
      "Test set: Average loss: 0.0457, Accuracy: 8583/10000 (85.8%)\n",
      "\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f7352e45ee0>\n",
      "Train Epoch: 1 [0/50000 (0.0%)]\tLoss: 2.620003\n",
      "Train Epoch: 1 [10000/50000 (20.0%)]\tLoss: 2.644393\n",
      "Train Epoch: 1 [20000/50000 (40.0%)]\tLoss: 2.658261\n",
      "Train Epoch: 1 [30000/50000 (60.0%)]\tLoss: 2.625230\n",
      "Train Epoch: 1 [40000/50000 (80.0%)]\tLoss: 2.518238\n",
      "\n",
      "Test set: Average loss: 0.0618, Accuracy: 8245/10000 (82.4%)\n",
      "\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f7352e45ee0>\n",
      "Train Epoch: 2 [0/50000 (0.0%)]\tLoss: 2.641109\n",
      "Train Epoch: 2 [10000/50000 (20.0%)]\tLoss: 2.574059\n",
      "Train Epoch: 2 [20000/50000 (40.0%)]\tLoss: 2.666578\n",
      "Train Epoch: 2 [30000/50000 (60.0%)]\tLoss: 2.676402\n",
      "Train Epoch: 2 [40000/50000 (80.0%)]\tLoss: 2.570243\n",
      "\n",
      "Test set: Average loss: 0.0371, Accuracy: 8679/10000 (86.8%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0388, Accuracy: 8679/10000 (86.8%)\n",
      "\n",
      "Typ:\n",
      "<class 'generator'>\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 3 \t total channel: 64 \t remaining channel: 22\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 6 \t total channel: 64 \t remaining channel: 58\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 10 \t total channel: 128 \t remaining channel: 117\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 13 \t total channel: 128 \t remaining channel: 112\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 17 \t total channel: 256 \t remaining channel: 209\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 20 \t total channel: 256 \t remaining channel: 197\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 24 \t total channel: 512 \t remaining channel: 331\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 27 \t total channel: 512 \t remaining channel: 295\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 31 \t total channel: 512 \t remaining channel: 257\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 34 \t total channel: 512 \t remaining channel: 21\n",
      "[22, 58, 'M', 117, 112, 'M', 209, 197, 'M', 331, 295, 'M', 257, 21]\n",
      "In shape: 3 Out shape:22\n",
      "In shape: 22 Out shape:58\n",
      "In shape: 58 Out shape:117\n",
      "In shape: 117 Out shape:112\n",
      "In shape: 112 Out shape:209\n",
      "In shape: 209 Out shape:197\n",
      "In shape: 197 Out shape:331\n",
      "In shape: 331 Out shape:295\n",
      "In shape: 295 Out shape:257\n",
      "In shape: 257 Out shape:21\n",
      "\n",
      "Test set: Average loss: 0.1665, Accuracy: 4209/10000 (42.1%)\n",
      "\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f7352e45ee0>\n",
      "Train Epoch: 0 [0/50000 (0.0%)]\tLoss: 2.952537\n",
      "Train Epoch: 0 [10000/50000 (20.0%)]\tLoss: 2.426526\n",
      "Train Epoch: 0 [20000/50000 (40.0%)]\tLoss: 2.506911\n",
      "Train Epoch: 0 [30000/50000 (60.0%)]\tLoss: 2.417577\n",
      "Train Epoch: 0 [40000/50000 (80.0%)]\tLoss: 2.564440\n",
      "\n",
      "Test set: Average loss: 0.0476, Accuracy: 8483/10000 (84.8%)\n",
      "\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f7352e45ee0>\n",
      "Train Epoch: 1 [0/50000 (0.0%)]\tLoss: 2.537918\n",
      "Train Epoch: 1 [10000/50000 (20.0%)]\tLoss: 2.560502\n",
      "Train Epoch: 1 [20000/50000 (40.0%)]\tLoss: 2.360982\n",
      "Train Epoch: 1 [30000/50000 (60.0%)]\tLoss: 2.442991\n",
      "Train Epoch: 1 [40000/50000 (80.0%)]\tLoss: 2.447009\n",
      "\n",
      "Test set: Average loss: 0.0541, Accuracy: 8406/10000 (84.1%)\n",
      "\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f7352e45ee0>\n",
      "Train Epoch: 2 [0/50000 (0.0%)]\tLoss: 2.412442\n",
      "Train Epoch: 2 [10000/50000 (20.0%)]\tLoss: 2.579464\n",
      "Train Epoch: 2 [20000/50000 (40.0%)]\tLoss: 2.590310\n",
      "Train Epoch: 2 [30000/50000 (60.0%)]\tLoss: 2.389052\n",
      "Train Epoch: 2 [40000/50000 (80.0%)]\tLoss: 2.547456\n",
      "\n",
      "Test set: Average loss: 0.0537, Accuracy: 8491/10000 (84.9%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0469, Accuracy: 8491/10000 (84.9%)\n",
      "\n",
      "Typ:\n",
      "<class 'generator'>\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 3 \t total channel: 64 \t remaining channel: 19\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 6 \t total channel: 64 \t remaining channel: 55\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 10 \t total channel: 128 \t remaining channel: 115\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 13 \t total channel: 128 \t remaining channel: 100\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 17 \t total channel: 256 \t remaining channel: 197\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 20 \t total channel: 256 \t remaining channel: 173\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 24 \t total channel: 512 \t remaining channel: 314\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 27 \t total channel: 512 \t remaining channel: 261\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 31 \t total channel: 512 \t remaining channel: 226\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 34 \t total channel: 512 \t remaining channel: 11\n",
      "[19, 55, 'M', 115, 100, 'M', 197, 173, 'M', 314, 261, 'M', 226, 11]\n",
      "In shape: 3 Out shape:19\n",
      "In shape: 19 Out shape:55\n",
      "In shape: 55 Out shape:115\n",
      "In shape: 115 Out shape:100\n",
      "In shape: 100 Out shape:197\n",
      "In shape: 197 Out shape:173\n",
      "In shape: 173 Out shape:314\n",
      "In shape: 314 Out shape:261\n",
      "In shape: 261 Out shape:226\n",
      "In shape: 226 Out shape:11\n",
      "\n",
      "Test set: Average loss: 0.1972, Accuracy: 3045/10000 (30.5%)\n",
      "\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f7352e45ee0>\n",
      "Train Epoch: 0 [0/50000 (0.0%)]\tLoss: 3.246356\n",
      "Train Epoch: 0 [10000/50000 (20.0%)]\tLoss: 2.353198\n",
      "Train Epoch: 0 [20000/50000 (40.0%)]\tLoss: 2.546743\n",
      "Train Epoch: 0 [30000/50000 (60.0%)]\tLoss: 2.472676\n",
      "Train Epoch: 0 [40000/50000 (80.0%)]\tLoss: 2.326373\n",
      "\n",
      "Test set: Average loss: 0.0429, Accuracy: 8448/10000 (84.5%)\n",
      "\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f7352e45ee0>\n",
      "Train Epoch: 1 [0/50000 (0.0%)]\tLoss: 2.353880\n",
      "Train Epoch: 1 [10000/50000 (20.0%)]\tLoss: 2.275334\n",
      "Train Epoch: 1 [20000/50000 (40.0%)]\tLoss: 2.481271\n",
      "Train Epoch: 1 [30000/50000 (60.0%)]\tLoss: 2.397531\n",
      "Train Epoch: 1 [40000/50000 (80.0%)]\tLoss: 2.502037\n",
      "\n",
      "Test set: Average loss: 0.0539, Accuracy: 8358/10000 (83.6%)\n",
      "\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f7352e45ee0>\n",
      "Train Epoch: 2 [0/50000 (0.0%)]\tLoss: 2.289825\n",
      "Train Epoch: 2 [10000/50000 (20.0%)]\tLoss: 2.451257\n",
      "Train Epoch: 2 [20000/50000 (40.0%)]\tLoss: 2.506855\n",
      "Train Epoch: 2 [30000/50000 (60.0%)]\tLoss: 2.310504\n",
      "Train Epoch: 2 [40000/50000 (80.0%)]\tLoss: 2.383204\n",
      "\n",
      "Test set: Average loss: 0.0326, Accuracy: 8667/10000 (86.7%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0403, Accuracy: 8667/10000 (86.7%)\n",
      "\n",
      "Typ:\n",
      "<class 'generator'>\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 3 \t total channel: 64 \t remaining channel: 17\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 6 \t total channel: 64 \t remaining channel: 50\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 10 \t total channel: 128 \t remaining channel: 109\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 13 \t total channel: 128 \t remaining channel: 92\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 17 \t total channel: 256 \t remaining channel: 174\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 20 \t total channel: 256 \t remaining channel: 152\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 24 \t total channel: 512 \t remaining channel: 281\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 27 \t total channel: 512 \t remaining channel: 239\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 31 \t total channel: 512 \t remaining channel: 204\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 34 \t total channel: 512 \t remaining channel: 6\n",
      "[17, 50, 'M', 109, 92, 'M', 174, 152, 'M', 281, 239, 'M', 204, 6]\n",
      "In shape: 3 Out shape:17\n",
      "In shape: 17 Out shape:50\n",
      "In shape: 50 Out shape:109\n",
      "In shape: 109 Out shape:92\n",
      "In shape: 92 Out shape:174\n",
      "In shape: 174 Out shape:152\n",
      "In shape: 152 Out shape:281\n",
      "In shape: 281 Out shape:239\n",
      "In shape: 239 Out shape:204\n",
      "In shape: 204 Out shape:6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.2317, Accuracy: 1124/10000 (11.2%)\n",
      "\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f7352e45ee0>\n",
      "Train Epoch: 0 [0/50000 (0.0%)]\tLoss: 3.382720\n",
      "Train Epoch: 0 [10000/50000 (20.0%)]\tLoss: 2.376612\n",
      "Train Epoch: 0 [20000/50000 (40.0%)]\tLoss: 2.370102\n",
      "Train Epoch: 0 [30000/50000 (60.0%)]\tLoss: 2.288261\n",
      "Train Epoch: 0 [40000/50000 (80.0%)]\tLoss: 2.235248\n",
      "\n",
      "Test set: Average loss: 0.0497, Accuracy: 8368/10000 (83.7%)\n",
      "\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f7352e45ee0>\n",
      "Train Epoch: 1 [0/50000 (0.0%)]\tLoss: 2.214203\n",
      "Train Epoch: 1 [10000/50000 (20.0%)]\tLoss: 2.559456\n",
      "Train Epoch: 1 [20000/50000 (40.0%)]\tLoss: 2.249001\n",
      "Train Epoch: 1 [30000/50000 (60.0%)]\tLoss: 2.387926\n",
      "Train Epoch: 1 [40000/50000 (80.0%)]\tLoss: 2.186004\n",
      "\n",
      "Test set: Average loss: 0.0389, Accuracy: 8600/10000 (86.0%)\n",
      "\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f7352e45ee0>\n",
      "Train Epoch: 2 [0/50000 (0.0%)]\tLoss: 2.160975\n",
      "Train Epoch: 2 [10000/50000 (20.0%)]\tLoss: 2.246175\n",
      "Train Epoch: 2 [20000/50000 (40.0%)]\tLoss: 2.428882\n",
      "Train Epoch: 2 [30000/50000 (60.0%)]\tLoss: 2.257934\n",
      "Train Epoch: 2 [40000/50000 (80.0%)]\tLoss: 2.308443\n",
      "\n",
      "Test set: Average loss: 0.0579, Accuracy: 8393/10000 (83.9%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0487, Accuracy: 8393/10000 (83.9%)\n",
      "\n",
      "Typ:\n",
      "<class 'generator'>\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 3 \t total channel: 64 \t remaining channel: 14\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 6 \t total channel: 64 \t remaining channel: 48\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 10 \t total channel: 128 \t remaining channel: 100\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 13 \t total channel: 128 \t remaining channel: 74\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 17 \t total channel: 256 \t remaining channel: 157\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 20 \t total channel: 256 \t remaining channel: 130\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 24 \t total channel: 512 \t remaining channel: 262\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 27 \t total channel: 512 \t remaining channel: 204\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 31 \t total channel: 512 \t remaining channel: 186\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 34 \t total channel: 512 \t remaining channel: 2\n",
      "[14, 48, 'M', 100, 74, 'M', 157, 130, 'M', 262, 204, 'M', 186, 2]\n",
      "In shape: 3 Out shape:14\n",
      "In shape: 14 Out shape:48\n",
      "In shape: 48 Out shape:100\n",
      "In shape: 100 Out shape:74\n",
      "In shape: 74 Out shape:157\n",
      "In shape: 157 Out shape:130\n",
      "In shape: 130 Out shape:262\n",
      "In shape: 262 Out shape:204\n",
      "In shape: 204 Out shape:186\n",
      "In shape: 186 Out shape:2\n",
      "\n",
      "Test set: Average loss: 0.2317, Accuracy: 1374/10000 (13.7%)\n",
      "\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f7352e45ee0>\n",
      "Train Epoch: 0 [0/50000 (0.0%)]\tLoss: 3.742143\n",
      "Train Epoch: 0 [10000/50000 (20.0%)]\tLoss: 3.263375\n",
      "Train Epoch: 0 [20000/50000 (40.0%)]\tLoss: 2.736847\n",
      "Train Epoch: 0 [30000/50000 (60.0%)]\tLoss: 2.768422\n",
      "Train Epoch: 0 [40000/50000 (80.0%)]\tLoss: 2.728729\n",
      "\n",
      "Test set: Average loss: 0.0992, Accuracy: 7776/10000 (77.8%)\n",
      "\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f7352e45ee0>\n",
      "Train Epoch: 1 [0/50000 (0.0%)]\tLoss: 2.608641\n",
      "Train Epoch: 1 [10000/50000 (20.0%)]\tLoss: 2.520145\n",
      "Train Epoch: 1 [20000/50000 (40.0%)]\tLoss: 2.332758\n",
      "Train Epoch: 1 [30000/50000 (60.0%)]\tLoss: 2.449883\n",
      "Train Epoch: 1 [40000/50000 (80.0%)]\tLoss: 2.535853\n",
      "\n",
      "Test set: Average loss: 0.0724, Accuracy: 7946/10000 (79.5%)\n",
      "\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f7352e45ee0>\n",
      "Train Epoch: 2 [0/50000 (0.0%)]\tLoss: 2.365767\n",
      "Train Epoch: 2 [10000/50000 (20.0%)]\tLoss: 2.568835\n",
      "Train Epoch: 2 [20000/50000 (40.0%)]\tLoss: 2.656640\n",
      "Train Epoch: 2 [30000/50000 (60.0%)]\tLoss: 2.366149\n",
      "Train Epoch: 2 [40000/50000 (80.0%)]\tLoss: 2.456776\n",
      "\n",
      "Test set: Average loss: 0.0758, Accuracy: 7848/10000 (78.5%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0795, Accuracy: 7848/10000 (78.5%)\n",
      "\n",
      "Typ:\n",
      "<class 'generator'>\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 3 \t total channel: 64 \t remaining channel: 13\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 6 \t total channel: 64 \t remaining channel: 41\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 10 \t total channel: 128 \t remaining channel: 87\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 13 \t total channel: 128 \t remaining channel: 60\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 17 \t total channel: 256 \t remaining channel: 147\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 20 \t total channel: 256 \t remaining channel: 100\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 24 \t total channel: 512 \t remaining channel: 235\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 27 \t total channel: 512 \t remaining channel: 182\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 31 \t total channel: 512 \t remaining channel: 163\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 34 \t total channel: 512 \t remaining channel: 2\n",
      "[13, 41, 'M', 87, 60, 'M', 147, 100, 'M', 235, 182, 'M', 163, 2]\n",
      "In shape: 3 Out shape:13\n",
      "In shape: 13 Out shape:41\n",
      "In shape: 41 Out shape:87\n",
      "In shape: 87 Out shape:60\n",
      "In shape: 60 Out shape:147\n",
      "In shape: 147 Out shape:100\n",
      "In shape: 100 Out shape:235\n",
      "In shape: 235 Out shape:182\n",
      "In shape: 182 Out shape:163\n",
      "In shape: 163 Out shape:2\n",
      "\n",
      "Test set: Average loss: 0.2434, Accuracy: 1007/10000 (10.1%)\n",
      "\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f7352e45ee0>\n",
      "Train Epoch: 0 [0/50000 (0.0%)]\tLoss: 3.861293\n",
      "Train Epoch: 0 [10000/50000 (20.0%)]\tLoss: 3.074823\n",
      "Train Epoch: 0 [20000/50000 (40.0%)]\tLoss: 2.802294\n",
      "Train Epoch: 0 [30000/50000 (60.0%)]\tLoss: 2.621993\n",
      "Train Epoch: 0 [40000/50000 (80.0%)]\tLoss: 2.580971\n",
      "\n",
      "Test set: Average loss: 0.0957, Accuracy: 7389/10000 (73.9%)\n",
      "\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f7352e45ee0>\n",
      "Train Epoch: 1 [0/50000 (0.0%)]\tLoss: 2.369166\n",
      "Train Epoch: 1 [10000/50000 (20.0%)]\tLoss: 2.362489\n",
      "Train Epoch: 1 [20000/50000 (40.0%)]\tLoss: 2.326482\n",
      "Train Epoch: 1 [30000/50000 (60.0%)]\tLoss: 2.352427\n",
      "Train Epoch: 1 [40000/50000 (80.0%)]\tLoss: 2.292898\n",
      "\n",
      "Test set: Average loss: 0.0781, Accuracy: 7675/10000 (76.8%)\n",
      "\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f7352e45ee0>\n",
      "Train Epoch: 2 [0/50000 (0.0%)]\tLoss: 2.488180\n",
      "Train Epoch: 2 [10000/50000 (20.0%)]\tLoss: 2.298665\n",
      "Train Epoch: 2 [20000/50000 (40.0%)]\tLoss: 2.235308\n",
      "Train Epoch: 2 [30000/50000 (60.0%)]\tLoss: 2.399956\n",
      "Train Epoch: 2 [40000/50000 (80.0%)]\tLoss: 2.173681\n",
      "\n",
      "Test set: Average loss: 0.0813, Accuracy: 7783/10000 (77.8%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0858, Accuracy: 7783/10000 (77.8%)\n",
      "\n",
      "Typ:\n",
      "<class 'generator'>\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 3 \t total channel: 64 \t remaining channel: 13\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 6 \t total channel: 64 \t remaining channel: 34\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 10 \t total channel: 128 \t remaining channel: 79\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 13 \t total channel: 128 \t remaining channel: 49\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 17 \t total channel: 256 \t remaining channel: 124\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 20 \t total channel: 256 \t remaining channel: 78\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 24 \t total channel: 512 \t remaining channel: 210\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 27 \t total channel: 512 \t remaining channel: 157\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 31 \t total channel: 512 \t remaining channel: 139\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 34 \t total channel: 512 \t remaining channel: 0\n",
      "[13, 34, 'M', 79, 49, 'M', 124, 78, 'M', 210, 157, 'M', 139, 0]\n",
      "In shape: 3 Out shape:13\n",
      "In shape: 13 Out shape:34\n",
      "In shape: 34 Out shape:79\n",
      "In shape: 79 Out shape:49\n",
      "In shape: 49 Out shape:124\n",
      "In shape: 124 Out shape:78\n",
      "In shape: 78 Out shape:210\n",
      "In shape: 210 Out shape:157\n",
      "In shape: 157 Out shape:139\n",
      "\n",
      "Test set: Average loss: 0.5971, Accuracy: 1000/10000 (10.0%)\n",
      "\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f7352e45ee0>\n",
      "Train Epoch: 0 [0/50000 (0.0%)]\tLoss: 8.549303\n",
      "Train Epoch: 0 [10000/50000 (20.0%)]\tLoss: 1.809402\n",
      "Train Epoch: 0 [20000/50000 (40.0%)]\tLoss: 1.771950\n",
      "Train Epoch: 0 [30000/50000 (60.0%)]\tLoss: 1.758348\n",
      "Train Epoch: 0 [40000/50000 (80.0%)]\tLoss: 1.815292\n",
      "\n",
      "Test set: Average loss: 0.0492, Accuracy: 8244/10000 (82.4%)\n",
      "\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f7352e45ee0>\n",
      "Train Epoch: 1 [0/50000 (0.0%)]\tLoss: 1.966824\n",
      "Train Epoch: 1 [10000/50000 (20.0%)]\tLoss: 1.854561\n",
      "Train Epoch: 1 [20000/50000 (40.0%)]\tLoss: 1.656596\n",
      "Train Epoch: 1 [30000/50000 (60.0%)]\tLoss: 1.765998\n",
      "Train Epoch: 1 [40000/50000 (80.0%)]\tLoss: 1.723128\n",
      "\n",
      "Test set: Average loss: 0.0539, Accuracy: 8185/10000 (81.8%)\n",
      "\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f7352e45ee0>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [0/50000 (0.0%)]\tLoss: 1.793772\n",
      "Train Epoch: 2 [10000/50000 (20.0%)]\tLoss: 1.664721\n",
      "Train Epoch: 2 [20000/50000 (40.0%)]\tLoss: 1.811908\n",
      "Train Epoch: 2 [30000/50000 (60.0%)]\tLoss: 1.668042\n",
      "Train Epoch: 2 [40000/50000 (80.0%)]\tLoss: 1.933366\n",
      "\n",
      "Test set: Average loss: 0.0510, Accuracy: 8317/10000 (83.2%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0532, Accuracy: 8317/10000 (83.2%)\n",
      "\n",
      "Typ:\n",
      "<class 'generator'>\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 3 \t total channel: 64 \t remaining channel: 13\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 6 \t total channel: 64 \t remaining channel: 26\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 10 \t total channel: 128 \t remaining channel: 66\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 13 \t total channel: 128 \t remaining channel: 39\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 17 \t total channel: 256 \t remaining channel: 97\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 20 \t total channel: 256 \t remaining channel: 57\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 24 \t total channel: 512 \t remaining channel: 180\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 27 \t total channel: 512 \t remaining channel: 136\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 31 \t total channel: 512 \t remaining channel: 121\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 34 \t total channel: 512 \t remaining channel: 0\n",
      "[13, 26, 'M', 66, 39, 'M', 97, 57, 'M', 180, 136, 'M', 121, 0]\n",
      "In shape: 3 Out shape:13\n",
      "In shape: 13 Out shape:26\n",
      "In shape: 26 Out shape:66\n",
      "In shape: 66 Out shape:39\n",
      "In shape: 39 Out shape:97\n",
      "In shape: 97 Out shape:57\n",
      "In shape: 57 Out shape:180\n",
      "In shape: 180 Out shape:136\n",
      "In shape: 136 Out shape:121\n",
      "\n",
      "Test set: Average loss: 0.6166, Accuracy: 1000/10000 (10.0%)\n",
      "\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f7352e45ee0>\n",
      "Train Epoch: 0 [0/50000 (0.0%)]\tLoss: 7.902066\n",
      "Train Epoch: 0 [10000/50000 (20.0%)]\tLoss: 1.943329\n",
      "Train Epoch: 0 [20000/50000 (40.0%)]\tLoss: 1.815471\n",
      "Train Epoch: 0 [30000/50000 (60.0%)]\tLoss: 1.663339\n",
      "Train Epoch: 0 [40000/50000 (80.0%)]\tLoss: 1.790455\n",
      "\n",
      "Test set: Average loss: 0.0591, Accuracy: 8097/10000 (81.0%)\n",
      "\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f7352e45ee0>\n",
      "Train Epoch: 1 [0/50000 (0.0%)]\tLoss: 1.759778\n",
      "Train Epoch: 1 [10000/50000 (20.0%)]\tLoss: 1.737662\n",
      "Train Epoch: 1 [20000/50000 (40.0%)]\tLoss: 1.842647\n",
      "Train Epoch: 1 [30000/50000 (60.0%)]\tLoss: 1.671531\n",
      "Train Epoch: 1 [40000/50000 (80.0%)]\tLoss: 1.549202\n",
      "\n",
      "Test set: Average loss: 0.0510, Accuracy: 8279/10000 (82.8%)\n",
      "\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f7352e45ee0>\n",
      "Train Epoch: 2 [0/50000 (0.0%)]\tLoss: 1.672748\n",
      "Train Epoch: 2 [10000/50000 (20.0%)]\tLoss: 1.702647\n",
      "Train Epoch: 2 [20000/50000 (40.0%)]\tLoss: 1.629716\n",
      "Train Epoch: 2 [30000/50000 (60.0%)]\tLoss: 1.539587\n",
      "Train Epoch: 2 [40000/50000 (80.0%)]\tLoss: 1.602812\n",
      "\n",
      "Test set: Average loss: 0.0503, Accuracy: 8332/10000 (83.3%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0495, Accuracy: 8332/10000 (83.3%)\n",
      "\n",
      "Typ:\n",
      "<class 'generator'>\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 3 \t total channel: 64 \t remaining channel: 12\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 6 \t total channel: 64 \t remaining channel: 21\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 10 \t total channel: 128 \t remaining channel: 55\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 13 \t total channel: 128 \t remaining channel: 28\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 17 \t total channel: 256 \t remaining channel: 71\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 20 \t total channel: 256 \t remaining channel: 43\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 24 \t total channel: 512 \t remaining channel: 146\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 27 \t total channel: 512 \t remaining channel: 109\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 31 \t total channel: 512 \t remaining channel: 103\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 34 \t total channel: 512 \t remaining channel: 0\n",
      "[12, 21, 'M', 55, 28, 'M', 71, 43, 'M', 146, 109, 'M', 103, 0]\n",
      "In shape: 3 Out shape:12\n",
      "In shape: 12 Out shape:21\n",
      "In shape: 21 Out shape:55\n",
      "In shape: 55 Out shape:28\n",
      "In shape: 28 Out shape:71\n",
      "In shape: 71 Out shape:43\n",
      "In shape: 43 Out shape:146\n",
      "In shape: 146 Out shape:109\n",
      "In shape: 109 Out shape:103\n",
      "\n",
      "Test set: Average loss: 0.6907, Accuracy: 1000/10000 (10.0%)\n",
      "\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f7352e45ee0>\n",
      "Train Epoch: 0 [0/50000 (0.0%)]\tLoss: 8.099217\n",
      "Train Epoch: 0 [10000/50000 (20.0%)]\tLoss: 2.367263\n",
      "Train Epoch: 0 [20000/50000 (40.0%)]\tLoss: 1.846323\n",
      "Train Epoch: 0 [30000/50000 (60.0%)]\tLoss: 1.641688\n",
      "Train Epoch: 0 [40000/50000 (80.0%)]\tLoss: 1.480467\n",
      "\n",
      "Test set: Average loss: 0.0671, Accuracy: 7886/10000 (78.9%)\n",
      "\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f7352e45ee0>\n",
      "Train Epoch: 1 [0/50000 (0.0%)]\tLoss: 1.641311\n",
      "Train Epoch: 1 [10000/50000 (20.0%)]\tLoss: 1.392095\n",
      "Train Epoch: 1 [20000/50000 (40.0%)]\tLoss: 1.482399\n",
      "Train Epoch: 1 [30000/50000 (60.0%)]\tLoss: 1.675799\n",
      "Train Epoch: 1 [40000/50000 (80.0%)]\tLoss: 1.565071\n",
      "\n",
      "Test set: Average loss: 0.0610, Accuracy: 7864/10000 (78.6%)\n",
      "\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f7352e45ee0>\n",
      "Train Epoch: 2 [0/50000 (0.0%)]\tLoss: 1.584972\n",
      "Train Epoch: 2 [10000/50000 (20.0%)]\tLoss: 1.385906\n",
      "Train Epoch: 2 [20000/50000 (40.0%)]\tLoss: 1.517492\n",
      "Train Epoch: 2 [30000/50000 (60.0%)]\tLoss: 1.566854\n",
      "Train Epoch: 2 [40000/50000 (80.0%)]\tLoss: 1.492501\n",
      "\n",
      "Test set: Average loss: 0.0568, Accuracy: 8135/10000 (81.3%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0557, Accuracy: 8135/10000 (81.3%)\n",
      "\n",
      "Typ:\n",
      "<class 'generator'>\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 3 \t total channel: 64 \t remaining channel: 9\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 6 \t total channel: 64 \t remaining channel: 13\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 10 \t total channel: 128 \t remaining channel: 42\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 13 \t total channel: 128 \t remaining channel: 16\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 17 \t total channel: 256 \t remaining channel: 53\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 20 \t total channel: 256 \t remaining channel: 26\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 24 \t total channel: 512 \t remaining channel: 113\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 27 \t total channel: 512 \t remaining channel: 89\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 31 \t total channel: 512 \t remaining channel: 80\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 34 \t total channel: 512 \t remaining channel: 0\n",
      "[9, 13, 'M', 42, 16, 'M', 53, 26, 'M', 113, 89, 'M', 80, 0]\n",
      "In shape: 3 Out shape:9\n",
      "In shape: 9 Out shape:13\n",
      "In shape: 13 Out shape:42\n",
      "In shape: 42 Out shape:16\n",
      "In shape: 16 Out shape:53\n",
      "In shape: 53 Out shape:26\n",
      "In shape: 26 Out shape:113\n",
      "In shape: 113 Out shape:89\n",
      "In shape: 89 Out shape:80\n",
      "\n",
      "Test set: Average loss: 0.6611, Accuracy: 1000/10000 (10.0%)\n",
      "\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f7352e45ee0>\n",
      "Train Epoch: 0 [0/50000 (0.0%)]\tLoss: 8.219998\n",
      "Train Epoch: 0 [10000/50000 (20.0%)]\tLoss: 2.257280\n",
      "Train Epoch: 0 [20000/50000 (40.0%)]\tLoss: 1.958650\n",
      "Train Epoch: 0 [30000/50000 (60.0%)]\tLoss: 1.725757\n",
      "Train Epoch: 0 [40000/50000 (80.0%)]\tLoss: 1.961597\n",
      "\n",
      "Test set: Average loss: 0.0905, Accuracy: 6864/10000 (68.6%)\n",
      "\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f7352e45ee0>\n",
      "Train Epoch: 1 [0/50000 (0.0%)]\tLoss: 1.782591\n",
      "Train Epoch: 1 [10000/50000 (20.0%)]\tLoss: 1.694378\n",
      "Train Epoch: 1 [20000/50000 (40.0%)]\tLoss: 1.701133\n",
      "Train Epoch: 1 [30000/50000 (60.0%)]\tLoss: 1.688586\n",
      "Train Epoch: 1 [40000/50000 (80.0%)]\tLoss: 1.398579\n",
      "\n",
      "Test set: Average loss: 0.0808, Accuracy: 7323/10000 (73.2%)\n",
      "\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f7352e45ee0>\n",
      "Train Epoch: 2 [0/50000 (0.0%)]\tLoss: 1.691458\n",
      "Train Epoch: 2 [10000/50000 (20.0%)]\tLoss: 1.666127\n",
      "Train Epoch: 2 [20000/50000 (40.0%)]\tLoss: 1.522030\n",
      "Train Epoch: 2 [30000/50000 (60.0%)]\tLoss: 1.247345\n",
      "Train Epoch: 2 [40000/50000 (80.0%)]\tLoss: 1.328364\n",
      "\n",
      "Test set: Average loss: 0.0682, Accuracy: 7489/10000 (74.9%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0768, Accuracy: 7489/10000 (74.9%)\n",
      "\n",
      "Typ:\n",
      "<class 'generator'>\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 3 \t total channel: 64 \t remaining channel: 8\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 6 \t total channel: 64 \t remaining channel: 7\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 10 \t total channel: 128 \t remaining channel: 23\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 13 \t total channel: 128 \t remaining channel: 4\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 17 \t total channel: 256 \t remaining channel: 26\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 20 \t total channel: 256 \t remaining channel: 16\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 24 \t total channel: 512 \t remaining channel: 83\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 27 \t total channel: 512 \t remaining channel: 69\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 31 \t total channel: 512 \t remaining channel: 58\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 34 \t total channel: 512 \t remaining channel: 0\n",
      "[8, 7, 'M', 23, 4, 'M', 26, 16, 'M', 83, 69, 'M', 58, 0]\n",
      "In shape: 3 Out shape:8\n",
      "In shape: 8 Out shape:7\n",
      "In shape: 7 Out shape:23\n",
      "In shape: 23 Out shape:4\n",
      "In shape: 4 Out shape:26\n",
      "In shape: 26 Out shape:16\n",
      "In shape: 16 Out shape:83\n",
      "In shape: 83 Out shape:69\n",
      "In shape: 69 Out shape:58\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.6852, Accuracy: 1000/10000 (10.0%)\n",
      "\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f7352e45ee0>\n",
      "Train Epoch: 0 [0/50000 (0.0%)]\tLoss: 6.826516\n",
      "Train Epoch: 0 [10000/50000 (20.0%)]\tLoss: 2.231735\n",
      "Train Epoch: 0 [20000/50000 (40.0%)]\tLoss: 2.091769\n",
      "Train Epoch: 0 [30000/50000 (60.0%)]\tLoss: 1.929709\n",
      "Train Epoch: 0 [40000/50000 (80.0%)]\tLoss: 1.980090\n",
      "\n",
      "Test set: Average loss: 0.1340, Accuracy: 5127/10000 (51.3%)\n",
      "\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f7352e45ee0>\n",
      "Train Epoch: 1 [0/50000 (0.0%)]\tLoss: 1.966749\n",
      "Train Epoch: 1 [10000/50000 (20.0%)]\tLoss: 1.856617\n",
      "Train Epoch: 1 [20000/50000 (40.0%)]\tLoss: 1.753056\n",
      "Train Epoch: 1 [30000/50000 (60.0%)]\tLoss: 1.848718\n",
      "Train Epoch: 1 [40000/50000 (80.0%)]\tLoss: 1.756794\n",
      "\n",
      "Test set: Average loss: 0.1277, Accuracy: 5612/10000 (56.1%)\n",
      "\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f7352e45ee0>\n",
      "Train Epoch: 2 [0/50000 (0.0%)]\tLoss: 1.701297\n",
      "Train Epoch: 2 [10000/50000 (20.0%)]\tLoss: 1.656715\n",
      "Train Epoch: 2 [20000/50000 (40.0%)]\tLoss: 1.520184\n",
      "Train Epoch: 2 [30000/50000 (60.0%)]\tLoss: 1.489017\n",
      "Train Epoch: 2 [40000/50000 (80.0%)]\tLoss: 1.556775\n",
      "\n",
      "Test set: Average loss: 0.1041, Accuracy: 6222/10000 (62.2%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.1078, Accuracy: 6222/10000 (62.2%)\n",
      "\n",
      "Typ:\n",
      "<class 'generator'>\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 3 \t total channel: 64 \t remaining channel: 7\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 6 \t total channel: 64 \t remaining channel: 3\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 10 \t total channel: 128 \t remaining channel: 7\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 13 \t total channel: 128 \t remaining channel: 0\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 17 \t total channel: 256 \t remaining channel: 7\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 20 \t total channel: 256 \t remaining channel: 4\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 24 \t total channel: 512 \t remaining channel: 42\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 27 \t total channel: 512 \t remaining channel: 44\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 31 \t total channel: 512 \t remaining channel: 33\n",
      "<class 'torch.Tensor'>\n",
      "layer index: 34 \t total channel: 512 \t remaining channel: 0\n",
      "[7, 3, 'M', 7, 0, 'M', 7, 4, 'M', 42, 44, 'M', 33, 0]\n",
      "In shape: 3 Out shape:7\n",
      "In shape: 7 Out shape:3\n",
      "In shape: 3 Out shape:7\n",
      "In shape: 7 Out shape:7\n",
      "In shape: 7 Out shape:4\n",
      "In shape: 4 Out shape:42\n",
      "In shape: 42 Out shape:44\n",
      "In shape: 44 Out shape:33\n",
      "\n",
      "Test set: Average loss: 0.4806, Accuracy: 1000/10000 (10.0%)\n",
      "\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f7352e45ee0>\n",
      "Train Epoch: 0 [0/50000 (0.0%)]\tLoss: 4.615427\n",
      "Train Epoch: 0 [10000/50000 (20.0%)]\tLoss: 2.439164\n",
      "Train Epoch: 0 [20000/50000 (40.0%)]\tLoss: 2.026372\n",
      "Train Epoch: 0 [30000/50000 (60.0%)]\tLoss: 1.934233\n",
      "Train Epoch: 0 [40000/50000 (80.0%)]\tLoss: 1.831648\n",
      "\n",
      "Test set: Average loss: 0.1508, Accuracy: 4257/10000 (42.6%)\n",
      "\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f7352e45ee0>\n",
      "Train Epoch: 1 [0/50000 (0.0%)]\tLoss: 1.688868\n",
      "Train Epoch: 1 [10000/50000 (20.0%)]\tLoss: 1.819049\n",
      "Train Epoch: 1 [20000/50000 (40.0%)]\tLoss: 1.984198\n",
      "Train Epoch: 1 [30000/50000 (60.0%)]\tLoss: 1.876328\n",
      "Train Epoch: 1 [40000/50000 (80.0%)]\tLoss: 1.641447\n",
      "\n",
      "Test set: Average loss: 0.1403, Accuracy: 4769/10000 (47.7%)\n",
      "\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f7352e45ee0>\n",
      "Train Epoch: 2 [0/50000 (0.0%)]\tLoss: 1.898006\n",
      "Train Epoch: 2 [10000/50000 (20.0%)]\tLoss: 1.641993\n",
      "Train Epoch: 2 [20000/50000 (40.0%)]\tLoss: 1.810690\n",
      "Train Epoch: 2 [30000/50000 (60.0%)]\tLoss: 1.899267\n",
      "Train Epoch: 2 [40000/50000 (80.0%)]\tLoss: 1.647118\n",
      "\n",
      "Test set: Average loss: 0.1428, Accuracy: 4774/10000 (47.7%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.1443, Accuracy: 4774/10000 (47.7%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_list = []\n",
    "fine_tune_epochs = 3\n",
    "steps = 20\n",
    "for i in range(1, steps):\n",
    "    raw_pruned = prune_model(model_sparsity, i/steps)\n",
    "    test_error = float(test(raw_pruned)[0])\n",
    "    fine_tuned = train_model(raw_pruned, epochs=fine_tune_epochs)\n",
    "    test_error_fine_tuned = float(test(fine_tuned)[0])\n",
    "    model_list.append({'model': fine_tuned, 'test_error': test_error, \n",
    "                       'fine_tuned_error': test_error_fine_tuned, 'prune_ratio': i/steps, \n",
    "                       'fine_tune_epochs': fine_tune_epochs})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3c33b10a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_error = []\n",
    "fine_tuned_error = []\n",
    "prune_ratio = []\n",
    "num_parameters = []\n",
    "for prune_set in model_list:\n",
    "    test_error.append(prune_set['test_error'])\n",
    "    fine_tuned_error.append(prune_set['fine_tuned_error'])\n",
    "    prune_ratio.append(prune_set['prune_ratio'])\n",
    "    num_parameters.append(sum(p.numel() for p in prune_set['model'].parameters()))\n",
    "\n",
    "\n",
    "fig, ax1 = plt.subplots()    \n",
    "\n",
    "color = 'tab:red'\n",
    "ax1.plot(prune_ratio, fine_tuned_error, color='tab:red', label='fine tuned acc')\n",
    "ax1.plot(prune_ratio, test_error, color='tab:green', label='raw acc')\n",
    "ax1.set_xlabel('prune ratio')\n",
    "ax1.set_ylabel('fine tuned accuracy')\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "plt.legend()\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "color = 'tab:blue'\n",
    "ax2.set_ylabel('num param', color=color)  # we already handled the x-label with ax1\n",
    "ax2.plot(prune_ratio, num_parameters, color=color, label='amount parameters')\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "ax2.set_yscale('linear')\n",
    "plt.legend()\n",
    "\n",
    "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "plt.grid(axis='both', color='black', linestyle=':', linewidth=1)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6fc14ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio: 0.050000, error: 0.875200, param:8714593\n",
      "ratio: 0.100000, error: 0.870800, param:7998149\n",
      "ratio: 0.150000, error: 0.862200, param:7263397\n",
      "ratio: 0.200000, error: 0.864100, param:6410242\n",
      "ratio: 0.250000, error: 0.841400, param:5636417\n",
      "ratio: 0.300000, error: 0.866900, param:4877118\n",
      "ratio: 0.350000, error: 0.874300, param:4184077\n",
      "ratio: 0.400000, error: 0.867900, param:3550860\n",
      "ratio: 0.450000, error: 0.849100, param:2972351\n",
      "ratio: 0.500000, error: 0.866700, param:2437166\n",
      "ratio: 0.550000, error: 0.839300, param:1970892\n",
      "ratio: 0.600000, error: 0.784800, param:1539278\n",
      "ratio: 0.650000, error: 0.778300, param:1164359\n",
      "ratio: 0.700000, error: 0.831700, param:848797\n",
      "ratio: 0.750000, error: 0.833200, param:589265\n",
      "ratio: 0.800000, error: 0.813500, param:375203\n",
      "ratio: 0.850000, error: 0.748900, param:215019\n",
      "ratio: 0.900000, error: 0.622200, param:108368\n",
      "ratio: 0.950000, error: 0.477400, param:33106\n"
     ]
    }
   ],
   "source": [
    "result = zip(prune_ratio, num_parameters, fine_tuned_error)\n",
    "for ratio, num, err in result:\n",
    "    print('ratio: {:f}, error: {:f}, param:{:d}'.format(ratio, err, num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "854e4a2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"safed = torch.load('pruned_model.pt')\\nstructure = safed['cfg']\\nweights = safed['state_dict']\\npruned_model = sequential_model(structure)\\npruned_model.load_state_dict(weights)\\npruned_model.cuda()\\nprec, loss = test(pruned_model)\""
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"safed = torch.load('pruned_model.pt')\n",
    "structure = safed['cfg']\n",
    "weights = safed['state_dict']\n",
    "pruned_model = sequential_model(structure)\n",
    "pruned_model.load_state_dict(weights)\n",
    "pruned_model.cuda()\n",
    "prec, loss = test(pruned_model)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2420286",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model_list[18]['model'], (3, 32, 32))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
